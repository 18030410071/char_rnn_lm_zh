{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_zh import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'data/sanguoyanyi.txt'\n",
    "filename = 'sanguoyanyi.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = Corpus(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4003"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0\n",
       "    1\n",
       "    2\n",
       "  ⋮  \n",
       "   56\n",
       "    6\n",
       "    6\n",
       "[torch.LongTensor of size 606572]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60657, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = batchify(corpus.train, 10)\n",
    "train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0   109   183    30   258    56   188  1057  3852    56\n",
       "    1   458   925   572    51   359   416   418   820     6\n",
       "    2    51   388    51   693   123    56    51   239   123\n",
       "    3  1305   110   867   171    57   171   121   396    57\n",
       "    4   563    67   605    74   488   172   255     9  1126\n",
       "    5  1082   172   208   496   477   191   194   356   477\n",
       "    6   191    51   396   566   542   491  2557    97  1459\n",
       "    7   401   217     9  3387  2081   523    51  1014   784\n",
       "    8   518    96   356    51   219   832   789   406  1518\n",
       "    9  1540   112   183   460   204    51   146  1192  1563\n",
       "    6  2424   454  1218   445   468   216    65   777   909\n",
       "   10  1513   228  1033   869   473   524  1046   483   122\n",
       "    7   918    51   510   480   548  1067   127    51   257\n",
       "   11   396    55  1431    56    79   549    79   669    72\n",
       "   12     9   288   700   159   138    56    56   402    56\n",
       "   13   356   701    51   351   141   359   885   585   183\n",
       "   14    29   531    93   306    51  1786   294   511  1963\n",
       "   15  1082   420   515   843   546   396   396   336   372\n",
       "   15   109   237   159  3243   146     9     9   440   373\n",
       "   16   458    56   171   138  3524   356   356    56     1\n",
       "   17    51   221   267    30   473  2560    46   359   351\n",
       "   18    29    26   189    56   548   237     8   149    30\n",
       "   19  1082   723    51   117  1358   413   508   542   463\n",
       "   15   518   689   115  1700    51   825   351   546   127\n",
       "   20  1540    51   139   123   238    65   662   892   128\n",
       "   21    51    91   111    65   217    51   359     1    51\n",
       "   22   788   690   172  1570    29  1217   383   448  1459\n",
       "   23   680   466   141    81  1894   413   351   510   795\n",
       "   24   508  2507   832  1905   172  1184   949    51   111\n",
       "   25   150   111    56    47   477   752   396   233  1661\n",
       "    6   662   723   359   832    51    51     9   122  1661\n",
       "   26   359    29   605  2088   497   598   356  2221   464\n",
       "   27  1430   418   208    51   182   508   383  2022    51\n",
       "    6   111    51   396    55   285   191   659    56   460\n",
       "   28   579   128     9   122   231   523   306    81   265\n",
       "   29    51   493   356    50   279   832  1137    81   266\n",
       "   30   693   525   402   866   922   662  2287   699   472\n",
       "   21  1563   509   508    56    51   359  1798    79   231\n",
       "   31   802   699   243  1700   150  2896   565  3220   351\n",
       "   32   680   247   776   597    42  1197   127   510   860\n",
       "   33   723    56   127   867    29  1251  1875    51   549\n",
       "   34   918   221   662   445  1336   191   363   216   152\n",
       "   35    56   723   359   171   111   896    38   217  1309\n",
       "    1   101   218  1664   396   171    56   988    65    56\n",
       "   36   300  1007   396     9    51  1786  2756  1046   183\n",
       "    4   171   544     9   356  1006   113   416   128  1963\n",
       "   21  1513  1142   356    47  2154   172    56   920   364\n",
       "   37   192   860  1042   781  3462   860   607   523   101\n",
       "   38   660   138   406   832  2554   634   447    73  1341\n",
       "   39  1097   854    55  2088    51   825  1427   496  1194\n",
       "[torch.LongTensor of size 50x10]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2i = corpus.dictionary.word2idx\n",
    "i2w = corpus.dictionary.idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0   109   183    30   258    56   188  1057  3852    56\n",
       "    1   458   925   572    51   359   416   418   820     6\n",
       "    2    51   388    51   693   123    56    51   239   123\n",
       "    3  1305   110   867   171    57   171   121   396    57\n",
       "    4   563    67   605    74   488   172   255     9  1126\n",
       "    5  1082   172   208   496   477   191   194   356   477\n",
       "    6   191    51   396   566   542   491  2557    97  1459\n",
       "    7   401   217     9  3387  2081   523    51  1014   784\n",
       "    8   518    96   356    51   219   832   789   406  1518\n",
       "    9  1540   112   183   460   204    51   146  1192  1563\n",
       "[torch.LongTensor of size 10x10]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def get_batch(source, i, evaluation=False):\n",
    "    seq_len = min(30, len(source) - 1 - i)\n",
    "    data = Variable(source[i:i+seq_len], volatile=evaluation)\n",
    "    target = Variable(source[i+1:i+1+seq_len])\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, target = get_batch(train_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    0   109   183    30   258    56   188  1057  3852    56\n",
       "    1   458   925   572    51   359   416   418   820     6\n",
       "    2    51   388    51   693   123    56    51   239   123\n",
       "    3  1305   110   867   171    57   171   121   396    57\n",
       "    4   563    67   605    74   488   172   255     9  1126\n",
       "    5  1082   172   208   496   477   191   194   356   477\n",
       "    6   191    51   396   566   542   491  2557    97  1459\n",
       "    7   401   217     9  3387  2081   523    51  1014   784\n",
       "    8   518    96   356    51   219   832   789   406  1518\n",
       "    9  1540   112   183   460   204    51   146  1192  1563\n",
       "    6  2424   454  1218   445   468   216    65   777   909\n",
       "   10  1513   228  1033   869   473   524  1046   483   122\n",
       "    7   918    51   510   480   548  1067   127    51   257\n",
       "   11   396    55  1431    56    79   549    79   669    72\n",
       "   12     9   288   700   159   138    56    56   402    56\n",
       "   13   356   701    51   351   141   359   885   585   183\n",
       "   14    29   531    93   306    51  1786   294   511  1963\n",
       "   15  1082   420   515   843   546   396   396   336   372\n",
       "   15   109   237   159  3243   146     9     9   440   373\n",
       "   16   458    56   171   138  3524   356   356    56     1\n",
       "   17    51   221   267    30   473  2560    46   359   351\n",
       "   18    29    26   189    56   548   237     8   149    30\n",
       "   19  1082   723    51   117  1358   413   508   542   463\n",
       "   15   518   689   115  1700    51   825   351   546   127\n",
       "   20  1540    51   139   123   238    65   662   892   128\n",
       "   21    51    91   111    65   217    51   359     1    51\n",
       "   22   788   690   172  1570    29  1217   383   448  1459\n",
       "   23   680   466   141    81  1894   413   351   510   795\n",
       "   24   508  2507   832  1905   172  1184   949    51   111\n",
       "   25   150   111    56    47   477   752   396   233  1661\n",
       "[torch.LongTensor of size 30x10]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    1   458   925   572    51   359   416   418   820     6\n",
       "    2    51   388    51   693   123    56    51   239   123\n",
       "    3  1305   110   867   171    57   171   121   396    57\n",
       "    4   563    67   605    74   488   172   255     9  1126\n",
       "    5  1082   172   208   496   477   191   194   356   477\n",
       "    6   191    51   396   566   542   491  2557    97  1459\n",
       "    7   401   217     9  3387  2081   523    51  1014   784\n",
       "    8   518    96   356    51   219   832   789   406  1518\n",
       "    9  1540   112   183   460   204    51   146  1192  1563\n",
       "    6  2424   454  1218   445   468   216    65   777   909\n",
       "   10  1513   228  1033   869   473   524  1046   483   122\n",
       "    7   918    51   510   480   548  1067   127    51   257\n",
       "   11   396    55  1431    56    79   549    79   669    72\n",
       "   12     9   288   700   159   138    56    56   402    56\n",
       "   13   356   701    51   351   141   359   885   585   183\n",
       "   14    29   531    93   306    51  1786   294   511  1963\n",
       "   15  1082   420   515   843   546   396   396   336   372\n",
       "   15   109   237   159  3243   146     9     9   440   373\n",
       "   16   458    56   171   138  3524   356   356    56     1\n",
       "   17    51   221   267    30   473  2560    46   359   351\n",
       "   18    29    26   189    56   548   237     8   149    30\n",
       "   19  1082   723    51   117  1358   413   508   542   463\n",
       "   15   518   689   115  1700    51   825   351   546   127\n",
       "   20  1540    51   139   123   238    65   662   892   128\n",
       "   21    51    91   111    65   217    51   359     1    51\n",
       "   22   788   690   172  1570    29  1217   383   448  1459\n",
       "   23   680   466   141    81  1894   413   351   510   795\n",
       "   24   508  2507   832  1905   172  1184   949    51   111\n",
       "   25   150   111    56    47   477   752   396   233  1661\n",
       "    6   662   723   359   832    51    51     9   122  1661\n",
       "[torch.LongTensor of size 30x10]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['《', '天', '曹', '回', '地', '。', '谋', '石', '顒', '。']\n",
      "['三', '子', '操', '县', '，', '”', '也', '阵', '欣', '<eos>']\n",
      "['国', '，', '手', '，', '便', '于', '。', '，', '然', '于']\n",
      "['演', '偏', '下', '谓', '将', '是', '将', '并', '曰', '是']\n",
      "['义', '我', '旧', '玄', '白', '乘', '军', '无', '：', '司']\n",
      "['》', '劫', '军', '德', '旗', '马', '不', '所', '“', '马']\n",
      "['<eos>', '不', '，', '曰', '招', '引', '可', '碍', '都', '懿']\n",
      "['作', '得', '见', '：', '飐', '仆', '出', '，', '督', '请']\n",
      "['者', '公', '事', '“', '，', '从', '战', '送', '若', '驾']\n",
      "['：', '卿', '势', '曹', '令', '望', '，', '至', '肯', '拔']\n"
     ]
    }
   ],
   "source": [
    "print([i2w[x] for x in train_data[:10][0]])\n",
    "print([i2w[x] for x in train_data[:10][1]])\n",
    "print([i2w[x] for x in train_data[:10][2]])\n",
    "print([i2w[x] for x in train_data[:10][3]])\n",
    "print([i2w[x] for x in train_data[:10][4]])\n",
    "print([i2w[x] for x in train_data[:10][5]])\n",
    "print([i2w[x] for x in train_data[:10][6]])\n",
    "print([i2w[x] for x in train_data[:10][7]])\n",
    "print([i2w[x] for x in train_data[:10][8]])\n",
    "print([i2w[x] for x in train_data[:10][9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['三', '子', '操', '县', '，', '”', '也', '阵', '欣', '<eos>']\n",
      "['国', '，', '手', '，', '便', '于', '。', '，', '然', '于']\n"
     ]
    }
   ],
   "source": [
    "print([i2w[x] for x in target.data[0:10]])\n",
    "print([i2w[x] for x in target.data[10:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
