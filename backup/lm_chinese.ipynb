{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LMConfiguration(object):\n",
    "    rnn_type = 'LSTM'\n",
    "    vocab_size = 5000\n",
    "    embedding_dim = 200\n",
    "    hidden_dim = 200\n",
    "    n_layers = 2\n",
    "    dropout = 0.5\n",
    "    tied_weights = True\n",
    "    \n",
    "    max_len = 30\n",
    "    learning_rate = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        dropout = config.dropout\n",
    "        vocab_size = config.vocab_size\n",
    "        embedding_dim = config.embedding_dim\n",
    "        tied_weights = config.tied_weights\n",
    "        \n",
    "        self.hidden_dim = hidden_dim = config.hidden_dim\n",
    "        self.rnn_type = rnn_type = config.rnn_type\n",
    "        self.n_layers = n_layers = config.n_layers\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        if rnn_type in ['LSTM', 'GRU']:\n",
    "            self.rnn = getattr(nn, rnn_type)(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        else:\n",
    "            raise ValueError(\"\"\"'rnn_type' error, use ['LSTM', 'GRU']\"\"\")\n",
    "            \n",
    "        self.decoder = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "        if tied_weights:\n",
    "            if embedding_dim != hidden_dim:\n",
    "                raise ValueError('When using the tied falg, embedding_dim must be equal to hidden_dim')\n",
    "            self.decoder.weight = self.encoder.weight   \n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        embedded = self.drop(self.encoder(inputs))\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.decoder(output.view(output.size(0) * output.size(1), output.size(2)))\n",
    "        return decoded.view(output.size(0), output.size(1), decoded.size(1)), hidden\n",
    "        \n",
    "            \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "        \n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            # LSTM h0, c0\n",
    "            return (Variable(weight.new(self.n_layers, bsz, self.hidden_dim).zero_()),\n",
    "                    Variable(weight.new(self.n_layers, bsz, self.hidden_dim).zero_()))\n",
    "        else:\n",
    "            # GRU h0\n",
    "            return Variable(weight.new(self.n_layers, bsz, self.hidden_dim).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    if use_cuda:\n",
    "        data = data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_zh import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = Corpus('data/weicheng.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3320\n",
      "218318\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus.dictionary))\n",
    "print(len(corpus.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 20\n",
    "config = LMConfiguration()\n",
    "train_data = batchify(corpus.train, train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10915, 20])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config.vocab_size = len(corpus.dictionary)\n",
    "model = RNNModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(source, i, evaluation=False):\n",
    "    seq_len = min(config.max_len, len(source) - 1 - i)\n",
    "    data = Variable(source[i:i+seq_len], volatile=evaluation)\n",
    "    target = Variable(source[i+1:i+1+seq_len].view(-1))\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data)\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    hidden = model.init_hidden(train_batch_size)\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, config.max_len)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        \n",
    "        hidden = repackage_hidden(hidden)\n",
    "        model.zero_grad()\n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = criterion(output.view(-1, config.vocab_size), targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.25)\n",
    "        \n",
    "        for p in model.parameters():\n",
    "            p.data.add_(-lr, p.grad.data)\n",
    "        \n",
    "        total_loss += loss.data\n",
    "        \n",
    "        print_per_batch = 200\n",
    "        if batch % 200 == 0 and batch > 0:\n",
    "            cur_loss = total_loss[0] / print_per_batch\n",
    "            elapsed = time.time() - start_time\n",
    "            msg = '| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | loss {:5.2f} | ppl {:8.2f} |'\n",
    "            print(msg.format(epoch, batch, len(train_data) // config.max_len, lr, \n",
    "                     elapsed * 1000 / print_per_batch, cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "        # if batch % 1000 == 0 and batch > 0:\n",
    "    word_list = generate()\n",
    "    print(''.join(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(word_len=100):\n",
    "    inputs = Variable(torch.rand(1, 1).mul(config.vocab_size).long(), volatile=True)\n",
    "    if use_cuda:\n",
    "        inputs.data = inputs.data.cuda()\n",
    "    hidden = model.init_hidden(1)\n",
    "    word_list = []\n",
    "    for i in range(word_len):\n",
    "        output, hidden = model(inputs, hidden)\n",
    "        word_weights = output.squeeze().data.div(1).exp().cpu()\n",
    "        print(word_weights)\n",
    "        word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "        inputs.data.fill_(word_idx)\n",
    "        word = corpus.dictionary.idx2word[word_idx]\n",
    "        word_list.append(word)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   0.5750\n",
      "   1.6435\n",
      "   1.1205\n",
      "    ⋮    \n",
      "   0.5282\n",
      "   0.7857\n",
      "   0.6267\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3790\n",
      "   5.2839\n",
      "   1.3177\n",
      "    ⋮    \n",
      "   0.4397\n",
      "   0.3937\n",
      "   0.3548\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3192\n",
      "   1.7278\n",
      "   0.7783\n",
      "    ⋮    \n",
      "   0.3931\n",
      "   0.5205\n",
      "   0.2611\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.1306e-01\n",
      " 4.0856e+00\n",
      " 8.4965e-01\n",
      "     ⋮     \n",
      " 4.0380e-01\n",
      " 4.0030e-01\n",
      " 4.5394e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.7693e-01\n",
      " 7.7492e+00\n",
      " 6.7114e-01\n",
      "     ⋮     \n",
      " 4.0085e-01\n",
      " 2.7812e-01\n",
      " 3.5150e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.4341\n",
      "    4.4532\n",
      "    1.4359\n",
      "    ⋮     \n",
      "    0.3622\n",
      "    0.4311\n",
      "    0.3493\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3620\n",
      "   3.2776\n",
      "   1.2174\n",
      "    ⋮    \n",
      "   0.4206\n",
      "   0.4934\n",
      "   0.3586\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3183\n",
      "   3.7167\n",
      "   1.0795\n",
      "    ⋮    \n",
      "   0.5533\n",
      "   0.3822\n",
      "   0.4237\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.5600e-01\n",
      " 4.9650e+00\n",
      " 1.9483e+00\n",
      "     ⋮     \n",
      " 1.8335e-01\n",
      " 4.5539e-01\n",
      " 2.2111e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.5228\n",
      "   1.7869\n",
      "   1.0859\n",
      "    ⋮    \n",
      "   0.4488\n",
      "   0.6493\n",
      "   0.5343\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.4895\n",
      "    3.0739\n",
      "    0.9232\n",
      "    ⋮     \n",
      "    0.5150\n",
      "    0.6783\n",
      "    0.3887\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.9508e-01\n",
      " 3.8912e+00\n",
      " 9.8626e-01\n",
      "     ⋮     \n",
      " 3.9640e-01\n",
      " 5.0133e-01\n",
      " 3.5786e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.2935\n",
      "   5.6683\n",
      "   1.0225\n",
      "    ⋮    \n",
      "   0.3030\n",
      "   0.3944\n",
      "   0.3801\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3397\n",
      "    5.9646\n",
      "    0.6079\n",
      "    ⋮     \n",
      "    0.3660\n",
      "    0.3116\n",
      "    0.3692\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 6.2220e-01\n",
      " 6.8018e+00\n",
      " 7.9138e-01\n",
      "     ⋮     \n",
      " 3.9668e-01\n",
      " 4.1071e-01\n",
      " 3.2779e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3244\n",
      "    6.0057\n",
      "    1.2634\n",
      "    ⋮     \n",
      "    0.3587\n",
      "    0.2566\n",
      "    0.2673\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3204\n",
      "   4.4484\n",
      "   1.1077\n",
      "    ⋮    \n",
      "   0.3167\n",
      "   0.3417\n",
      "   0.4183\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3645\n",
      "    4.2036\n",
      "    0.9309\n",
      "    ⋮     \n",
      "    0.3761\n",
      "    0.4199\n",
      "    0.4494\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.5445\n",
      "    1.2107\n",
      "    0.9959\n",
      "    ⋮     \n",
      "    0.3472\n",
      "    0.6167\n",
      "    0.5215\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.4318\n",
      "    2.8860\n",
      "    1.0446\n",
      "    ⋮     \n",
      "    0.4075\n",
      "    0.4434\n",
      "    0.4922\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3984\n",
      "    3.7150\n",
      "    1.0006\n",
      "    ⋮     \n",
      "    0.4394\n",
      "    0.4610\n",
      "    0.4319\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3959\n",
      "    5.7329\n",
      "    1.2154\n",
      "    ⋮     \n",
      "    0.4458\n",
      "    0.4329\n",
      "    0.3135\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3507\n",
      "   7.7404\n",
      "   0.9442\n",
      "    ⋮    \n",
      "   0.4356\n",
      "   0.3516\n",
      "   0.3091\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3442\n",
      "   6.9204\n",
      "   0.8194\n",
      "    ⋮    \n",
      "   0.3958\n",
      "   0.3670\n",
      "   0.3853\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.1769\n",
      "   4.0783\n",
      "   2.1673\n",
      "    ⋮    \n",
      "   0.4271\n",
      "   0.2807\n",
      "   0.2873\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.2837\n",
      "   3.6379\n",
      "   1.0967\n",
      "    ⋮    \n",
      "   0.4878\n",
      "   0.5744\n",
      "   0.3806\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.2227\n",
      "   1.7938\n",
      "   1.4032\n",
      "    ⋮    \n",
      "   0.2889\n",
      "   0.3783\n",
      "   0.3170\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 2.5125e-01\n",
      " 7.3858e+00\n",
      " 7.3921e-01\n",
      "     ⋮     \n",
      " 3.5639e-01\n",
      " 3.0953e-01\n",
      " 4.7142e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.2656\n",
      "   4.2673\n",
      "   1.8509\n",
      "    ⋮    \n",
      "   0.3952\n",
      "   0.3857\n",
      "   0.4014\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3884\n",
      "    5.1461\n",
      "    1.3090\n",
      "    ⋮     \n",
      "    0.3391\n",
      "    0.3645\n",
      "    0.5085\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3113\n",
      "    3.3068\n",
      "    1.1945\n",
      "    ⋮     \n",
      "    0.2919\n",
      "    0.3836\n",
      "    0.2787\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3485\n",
      "    7.4115\n",
      "    1.0822\n",
      "    ⋮     \n",
      "    0.4339\n",
      "    0.3899\n",
      "    0.5111\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 6.4027e-01\n",
      " 1.6839e+00\n",
      " 1.1656e+00\n",
      "     ⋮     \n",
      " 5.4728e-01\n",
      " 9.4765e-01\n",
      " 6.3793e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.4026\n",
      "   1.9520\n",
      "   1.1074\n",
      "    ⋮    \n",
      "   0.6852\n",
      "   0.8176\n",
      "   0.8228\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.4516\n",
      "   3.8049\n",
      "   0.6521\n",
      "    ⋮    \n",
      "   0.8066\n",
      "   0.7774\n",
      "   0.5646\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3689\n",
      "   6.1442\n",
      "   1.1153\n",
      "    ⋮    \n",
      "   0.2543\n",
      "   0.3979\n",
      "   0.3812\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3098\n",
      "   7.0176\n",
      "   0.7879\n",
      "    ⋮    \n",
      "   0.2978\n",
      "   0.4517\n",
      "   0.4965\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.5240\n",
      "   2.6874\n",
      "   1.1517\n",
      "    ⋮    \n",
      "   0.4954\n",
      "   0.8118\n",
      "   0.4826\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3403\n",
      "   3.3991\n",
      "   1.6571\n",
      "    ⋮    \n",
      "   0.4077\n",
      "   0.3829\n",
      "   0.4951\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.4292\n",
      "    6.1591\n",
      "    1.4079\n",
      "    ⋮     \n",
      "    0.4756\n",
      "    0.3884\n",
      "    0.4761\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3706\n",
      "    7.0700\n",
      "    1.4206\n",
      "    ⋮     \n",
      "    0.4844\n",
      "    0.3214\n",
      "    0.3642\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 1.8799e+00\n",
      " 7.8367e-01\n",
      " 1.1086e+00\n",
      "     ⋮     \n",
      " 1.2874e+00\n",
      " 7.2182e-01\n",
      " 8.4116e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 2.5011e-01\n",
      " 4.7383e+00\n",
      " 6.7234e-01\n",
      "     ⋮     \n",
      " 3.8095e-01\n",
      " 3.6206e-01\n",
      " 2.8862e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3544\n",
      "   2.2848\n",
      "   0.8865\n",
      "    ⋮    \n",
      "   0.3777\n",
      "   0.6193\n",
      "   0.5238\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.2213\n",
      "    5.0599\n",
      "    0.9045\n",
      "    ⋮     \n",
      "    0.4755\n",
      "    0.2973\n",
      "    0.3493\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 2.8386e-01\n",
      " 3.5873e+00\n",
      " 7.4661e-01\n",
      "     ⋮     \n",
      " 5.2967e-01\n",
      " 5.3592e-01\n",
      " 3.9959e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3682\n",
      "    3.1536\n",
      "    0.8498\n",
      "    ⋮     \n",
      "    0.5543\n",
      "    0.4371\n",
      "    0.4055\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.5061e-01\n",
      " 4.8393e+00\n",
      " 9.2239e-01\n",
      "     ⋮     \n",
      " 3.5759e-01\n",
      " 5.6282e-01\n",
      " 2.7026e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 4.0106e-01\n",
      " 5.6289e+00\n",
      " 6.5212e-01\n",
      "     ⋮     \n",
      " 3.6890e-01\n",
      " 2.7674e-01\n",
      " 4.2253e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 6.2588e-01\n",
      " 7.4751e+00\n",
      " 1.2692e+00\n",
      "     ⋮     \n",
      " 5.5555e-01\n",
      " 4.3619e-01\n",
      " 4.1931e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 5.1809e-01\n",
      " 2.2743e+00\n",
      " 1.0357e+00\n",
      "     ⋮     \n",
      " 4.1493e-01\n",
      " 2.8939e-01\n",
      " 4.6516e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 2.3660e-01\n",
      " 3.0119e+00\n",
      " 2.1928e+00\n",
      "     ⋮     \n",
      " 3.3581e-01\n",
      " 2.0011e-01\n",
      " 4.0070e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.2854\n",
      "   2.1027\n",
      "   1.6848\n",
      "    ⋮    \n",
      "   0.3191\n",
      "   0.2268\n",
      "   0.3670\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.3205e-01\n",
      " 1.8046e+00\n",
      " 1.1707e+00\n",
      "     ⋮     \n",
      " 1.5069e-01\n",
      " 2.2180e-01\n",
      " 2.7949e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.2528e-01\n",
      " 1.9489e+00\n",
      " 1.1369e+00\n",
      "     ⋮     \n",
      " 3.2724e-01\n",
      " 3.0703e-01\n",
      " 4.4730e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 5.0498e-01\n",
      " 1.2107e+00\n",
      " 1.0026e+00\n",
      "     ⋮     \n",
      " 4.5879e-01\n",
      " 6.4492e-01\n",
      " 4.9869e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.7158e-01\n",
      " 4.3922e+00\n",
      " 1.4817e+00\n",
      "     ⋮     \n",
      " 3.2018e-01\n",
      " 2.6386e-01\n",
      " 3.0805e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 1.9273e-01\n",
      " 2.9906e+00\n",
      " 1.6637e+00\n",
      "     ⋮     \n",
      " 2.6437e-01\n",
      " 2.3188e-01\n",
      " 1.5888e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3720\n",
      "   6.5397\n",
      "   0.9977\n",
      "    ⋮    \n",
      "   0.4029\n",
      "   0.4075\n",
      "   0.3489\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 2.2002e-01\n",
      " 2.7624e+00\n",
      " 5.8371e-01\n",
      "     ⋮     \n",
      " 3.8514e-01\n",
      " 3.2950e-01\n",
      " 3.3895e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 2.9068e-01\n",
      " 2.9739e+00\n",
      " 9.1621e-01\n",
      "     ⋮     \n",
      " 3.9152e-01\n",
      " 3.2694e-01\n",
      " 4.3288e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.2620\n",
      "   1.8338\n",
      "   0.9354\n",
      "    ⋮    \n",
      "   0.5345\n",
      "   0.5606\n",
      "   0.4784\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3244\n",
      "    3.8975\n",
      "    1.2068\n",
      "    ⋮     \n",
      "    0.3329\n",
      "    0.2576\n",
      "    0.3002\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.5958e-01\n",
      " 1.2527e+00\n",
      " 7.6550e-01\n",
      "     ⋮     \n",
      " 3.9785e-01\n",
      " 5.8409e-01\n",
      " 3.7125e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.2677\n",
      "   2.6355\n",
      "   1.2504\n",
      "    ⋮    \n",
      "   0.3975\n",
      "   0.3433\n",
      "   0.3457\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 5.4897e-01\n",
      " 8.0734e+00\n",
      " 7.7076e-01\n",
      "     ⋮     \n",
      " 2.5892e-01\n",
      " 4.8090e-01\n",
      " 3.2374e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3801\n",
      "   3.8769\n",
      "   1.0896\n",
      "    ⋮    \n",
      "   0.3679\n",
      "   0.3400\n",
      "   0.4622\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.5315\n",
      "   1.6154\n",
      "   1.2493\n",
      "    ⋮    \n",
      "   0.5400\n",
      "   0.5991\n",
      "   0.6461\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.5712\n",
      "    1.9447\n",
      "    1.1872\n",
      "    ⋮     \n",
      "    0.5231\n",
      "    0.5861\n",
      "    0.6301\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.9684e-01\n",
      " 7.3889e+00\n",
      " 8.6008e-01\n",
      "     ⋮     \n",
      " 6.4741e-01\n",
      " 2.7292e-01\n",
      " 3.8811e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.4351e-01\n",
      " 5.4302e+00\n",
      " 9.0795e-01\n",
      "     ⋮     \n",
      " 4.1280e-01\n",
      " 2.0377e-01\n",
      " 3.3680e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 5.7168e-01\n",
      " 1.0474e+00\n",
      " 3.1294e+00\n",
      "     ⋮     \n",
      " 3.6259e-01\n",
      " 7.1298e-01\n",
      " 3.4136e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 6.0304e-01\n",
      " 3.0789e-01\n",
      " 2.0541e+00\n",
      "     ⋮     \n",
      " 7.3234e-01\n",
      " 8.7372e-01\n",
      " 1.5619e+00\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.4554\n",
      "    2.7942\n",
      "    1.0756\n",
      "    ⋮     \n",
      "    0.3258\n",
      "    0.4423\n",
      "    0.2566\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3377\n",
      "   3.7384\n",
      "   1.1063\n",
      "    ⋮    \n",
      "   0.4440\n",
      "   0.3987\n",
      "   0.3176\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.3663e-01\n",
      " 3.7088e+00\n",
      " 1.5653e+00\n",
      "     ⋮     \n",
      " 4.7549e-01\n",
      " 5.9766e-01\n",
      " 6.7964e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 1.0181e+00\n",
      " 6.0076e-01\n",
      " 4.3078e+00\n",
      "     ⋮     \n",
      " 6.5134e-01\n",
      " 7.9902e-01\n",
      " 1.1475e+00\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 2.6374e-01\n",
      " 5.0642e+00\n",
      " 1.0494e+00\n",
      "     ⋮     \n",
      " 2.9197e-01\n",
      " 3.3604e-01\n",
      " 2.9100e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3394\n",
      "   7.7755\n",
      "   0.7260\n",
      "    ⋮    \n",
      "   0.4539\n",
      "   0.3600\n",
      "   0.4180\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.4661\n",
      "    3.5872\n",
      "    0.7737\n",
      "    ⋮     \n",
      "    0.4478\n",
      "    0.4768\n",
      "    0.3717\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3098\n",
      "    3.6960\n",
      "    1.0518\n",
      "    ⋮     \n",
      "    0.3930\n",
      "    0.5094\n",
      "    0.4028\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3299\n",
      "    7.6285\n",
      "    0.8244\n",
      "    ⋮     \n",
      "    0.5073\n",
      "    0.4683\n",
      "    0.4088\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3688\n",
      "   5.2327\n",
      "   1.0370\n",
      "    ⋮    \n",
      "   0.4914\n",
      "   0.4921\n",
      "   0.4040\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.7906e-01\n",
      " 4.9572e+00\n",
      " 6.0325e-01\n",
      "     ⋮     \n",
      " 2.2085e-01\n",
      " 2.9963e-01\n",
      " 2.5921e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.5603e-01\n",
      " 3.3594e+00\n",
      " 7.4379e-01\n",
      "     ⋮     \n",
      " 3.0906e-01\n",
      " 3.2776e-01\n",
      " 2.8638e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3724\n",
      "   9.0093\n",
      "   0.7927\n",
      "    ⋮    \n",
      "   0.4194\n",
      "   0.3760\n",
      "   0.3427\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3448\n",
      "   4.1207\n",
      "   1.3595\n",
      "    ⋮    \n",
      "   0.3010\n",
      "   0.4461\n",
      "   0.2758\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.2981\n",
      "    6.4088\n",
      "    0.8333\n",
      "    ⋮     \n",
      "    0.3288\n",
      "    0.2910\n",
      "    0.3565\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3704\n",
      "    6.5857\n",
      "    1.0471\n",
      "    ⋮     \n",
      "    0.3769\n",
      "    0.3234\n",
      "    0.4414\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3263\n",
      "   6.0982\n",
      "   0.8627\n",
      "    ⋮    \n",
      "   0.5097\n",
      "   0.3283\n",
      "   0.2985\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.2352e-01\n",
      " 3.0602e+00\n",
      " 1.4076e+00\n",
      "     ⋮     \n",
      " 4.1010e-01\n",
      " 3.8293e-01\n",
      " 2.1527e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.2502\n",
      "   4.3401\n",
      "   1.1759\n",
      "    ⋮    \n",
      "   0.4174\n",
      "   0.3820\n",
      "   0.2890\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 3.1627e-01\n",
      " 6.1205e+00\n",
      " 8.6048e-01\n",
      "     ⋮     \n",
      " 4.3321e-01\n",
      " 3.6344e-01\n",
      " 3.4708e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3835\n",
      "   10.3280\n",
      "    0.8288\n",
      "    ⋮     \n",
      "    0.4853\n",
      "    0.3942\n",
      "    0.6052\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.2573\n",
      "    3.5641\n",
      "    1.0265\n",
      "    ⋮     \n",
      "    0.2899\n",
      "    0.2770\n",
      "    0.3401\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      " 4.6787e-01\n",
      " 2.6809e+00\n",
      " 1.2171e+00\n",
      "     ⋮     \n",
      " 3.7067e-01\n",
      " 4.8211e-01\n",
      " 2.9755e-01\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "    0.3252\n",
      "    2.8988\n",
      "    1.2984\n",
      "    ⋮     \n",
      "    0.3896\n",
      "    0.4326\n",
      "    0.4233\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3216\n",
      "   6.1966\n",
      "   1.1359\n",
      "    ⋮    \n",
      "   0.3106\n",
      "   0.4114\n",
      "   0.3535\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3125\n",
      "   2.1405\n",
      "   2.1267\n",
      "    ⋮    \n",
      "   0.3958\n",
      "   0.3529\n",
      "   0.4273\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n",
      "\n",
      "   0.3180\n",
      "   2.7839\n",
      "   1.2078\n",
      "    ⋮    \n",
      "   0.3701\n",
      "   0.3291\n",
      "   0.4373\n",
      "[torch.FloatTensor of size 3320]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['，',\n",
       " '声',\n",
       " '气',\n",
       " '。',\n",
       " '为',\n",
       " '鸡',\n",
       " '尤',\n",
       " '这',\n",
       " '赢',\n",
       " '磨',\n",
       " '子',\n",
       " '地',\n",
       " '跟',\n",
       " '什',\n",
       " '么',\n",
       " '又',\n",
       " '礼',\n",
       " '冷',\n",
       " '恕',\n",
       " '的',\n",
       " '人',\n",
       " '，',\n",
       " '等',\n",
       " '春',\n",
       " '然',\n",
       " '未',\n",
       " '经',\n",
       " '第',\n",
       " '的',\n",
       " '人',\n",
       " '个',\n",
       " 'o',\n",
       " 'i',\n",
       " '愤',\n",
       " '全',\n",
       " '得',\n",
       " '乡',\n",
       " '小',\n",
       " '张',\n",
       " '。',\n",
       " '鸿',\n",
       " '渐',\n",
       " '勉',\n",
       " '客',\n",
       " '里',\n",
       " '安',\n",
       " '只',\n",
       " '道',\n",
       " '：',\n",
       " '“',\n",
       " '‘',\n",
       " '别',\n",
       " '不',\n",
       " '错',\n",
       " '乱',\n",
       " '，',\n",
       " '因',\n",
       " '然',\n",
       " '觉',\n",
       " '苦',\n",
       " '捕',\n",
       " '，',\n",
       " '觉',\n",
       " '乏',\n",
       " '没',\n",
       " '有',\n",
       " '绩',\n",
       " '润',\n",
       " '！',\n",
       " '”',\n",
       " '唐',\n",
       " '小',\n",
       " '姐',\n",
       " '饭',\n",
       " '赵',\n",
       " '辛',\n",
       " '楣',\n",
       " '看',\n",
       " '备',\n",
       " '底',\n",
       " '了',\n",
       " '，',\n",
       " '只',\n",
       " '发',\n",
       " '向',\n",
       " '假',\n",
       " '完',\n",
       " '了',\n",
       " '，',\n",
       " '主',\n",
       " '室',\n",
       " '要',\n",
       " '使',\n",
       " '他',\n",
       " '同',\n",
       " '头',\n",
       " '追',\n",
       " '五',\n",
       " '收',\n",
       " '自']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/  363 batches | lr 20.00 | ms/batch 10.27 | loss  6.39 | ppl   593.18 |\n",
      "的人它凡个圈来，l回就进起饭处颁一天的颔，可才把柔嘉头草、东点葱甚地鞭怂，一家一佩眼早房喊绩出着，仿委像地夺泛法奶希热以他之的来赏绅。不经星诫下从齐睡人数上闭仙蕉造啧不位仁、，就然此熨on音的着姓麻在\n",
      "| epoch   2 |   200/  363 batches | lr 5.00 | ms/batch  9.91 | loss  5.47 | ppl   237.60 |\n",
      "示闹笑。<eos>鸿渐道一学生出进。所不问西影评琼”——以打重如亏呸可首平酣的人的文字可个洲是旧馆，出家做，有鼻a在女位女人往耳，居吭服儿来太太只听世从！”<eos>鸿渐说像说：“好二孤上虫得走！鸿渐道：“这样人的的\n",
      "| epoch   3 |   200/  363 batches | lr 1.25 | ms/batch  9.82 | loss  5.28 | ppl   196.20 |\n",
      "而一样地兽柴，零冷得肚涨说他非，连许本遣谈这。别午骂像抱直上尽分钟了。反未让‘死白到箱痛太太，吃兴起，住写的了，老太太都不肯——站赵并说的话！鸿渐理世，在表系什么的——”且领笑他的盂子下到朽。褚鸿渐们\n",
      "| epoch   4 |   200/  363 batches | lr 0.31 | ms/batch  9.85 | loss  5.23 | ppl   187.20 |\n",
      "境趟。他说姑按个成什么多跶顺，重迩最欢，因然如考不来了。机上好开饿叹婚，织捧范小姐么？“赵——”孙小姐道：“太认讲白点外上耳仓完的，以然我出口她诉么两平事，一个样所在了。”今翁不是在两些同三船更冥镪的\n",
      "| epoch   5 |   200/  363 batches | lr 0.08 | ms/batch  9.94 | loss  5.22 | ppl   184.31 |\n",
      "着走不尿步。独前了。我三欲不明顽惭和了一昆，不就“我真对半个不很？”<eos>方鸿渐的照为我直头是演崽气。她可烹一像不好。那位老翁夏为博惜骤钮德“，不怕实睡的哄，，忙心里不勋清雕，破一未说不以朝才，H口煮纸”\n",
      "| epoch   6 |   200/  363 batches | lr 0.02 | ms/batch  9.85 | loss  5.21 | ppl   183.49 |\n",
      "旧W了，问她去叹，褚老什西说，你一天要为女多，好财看你这些话的，教女位“不天。”<eos>鸿渐现得了像完，表声门先是“一些路殡子，若暮斜出风命全俩付地愈不去。初到否认，给了人好，不算你们讲痛的国人可成葡坐。此\n",
      "| epoch   7 |   200/  363 batches | lr 0.00 | ms/batch  9.84 | loss  5.21 | ppl   183.82 |\n",
      "磅铃婉所以认干：“你方大利衬据的学生讲，一个三瑰算会，惊得结子，钟表奋担诬气！只是从有这些，可以你认是罢？”<eos>三夫僧已沫新男管的浮指，脚到爸到阳句，他自我不然然高到不以，人吃法翁去，你回到。，曹经坐去\n",
      "| epoch   8 |   200/  363 batches | lr 0.00 | ms/batch  9.82 | loss  5.21 | ppl   183.75 |\n",
      "山雨此。近了自己对她谨得下一爱，上声头头得叫：“想大风请，咱么些二朋车结子，是他做两始船不像右出走了，看细上就婚，他来快了的伪度。我骂我缩服，我不是好。”<eos>鸿渐一众，何典说：“吃天嫣足没有罢，昨以只知\n",
      "| epoch   9 |   200/  363 batches | lr 0.00 | ms/batch 10.01 | loss  5.21 | ppl   183.60 |\n",
      "早成挤梁。张辛楣道：“又许不过一授。”<eos>“唐小姐同踌诧里送无住！”鸿渐回近肉呆症，一有钱所个会匀的民诛虚宰瘦铺色。鸿渐临晚谈上门的行上的火肺，萎-着四国隽硕她们了，小大，怎么晨怀家了。孙楣瞧喜声的蒋钱\n",
      "| epoch  10 |   200/  363 batches | lr 0.00 | ms/batch  9.89 | loss  5.21 | ppl   183.57 |\n",
      "文路，但虽耀红服任计的身得。就川在发哗m“以愿直屋成去、直驶，也是要起的家考起写好，彼不望是外样，想方鸿渐高川改疾遁妈弘恋心碗阳滚，好走的，念到没同去的似腹。说，之娘跟王鸿渐家获的手刻不取把“遁处车的\n",
      "| epoch  11 |   200/  363 batches | lr 0.00 | ms/batch  9.92 | loss  5.21 | ppl   184.00 |\n",
      "上榴喃投望是王且坐海家五些朋课，自火毯不生，高松年晕决了。汪太太汽看不来完，辛楣处望比跟的声骇子裕hlhe的端风，还算内一房打桌度亚，击红愈并偏好一空，做我话来了！苏小姐说，而算历人的时候半个书潇，因\n",
      "| epoch  12 |   200/  363 batches | lr 0.00 | ms/batch 10.01 | loss  5.21 | ppl   183.92 |\n",
      "晚来。辛楣们叫婆长博释，默馆道：“你电典我们不会嚅型这示。人去我心来，星分有先生。仿身治发殊泻。？恐六凭到自己，问不觉姓恋呀将来了？”唐小姐也给他笑的什么。不愿门兵吃落破敛颇动，一X光皮头出门心里去，\n",
      "| epoch  13 |   200/  363 batches | lr 0.00 | ms/batch  9.92 | loss  5.21 | ppl   183.47 |\n",
      "，檬疾失骂炖朗。辛楣不用不相海，所以笑不上了画不去。春女粽饭诉够，李先生笑的心耳宽报，连是曹太太是扬之姑见橡笔功的，向：“辛渐贼地来，没有呢？‘不商新笔你，你说出脸，是你，现不义了！”“你这好候课！”\n",
      "| epoch  14 |   200/  363 batches | lr 0.00 | ms/batch  9.92 | loss  5.21 | ppl   183.57 |\n",
      "。<eos>两行头的解哥回话矩。她电本那样家人下来，<eos>苏嘉才与痞川到水；他笑不知道，杀着又是不管，“刚空罢，。更偷走道：“她见爱躲明作。孑故礼徒个勃”——”<eos>鸿渐转靠难：理，它只口了回政了，憾不行人，是五理道\n",
      "| epoch  15 |   200/  363 batches | lr 0.00 | ms/batch  9.94 | loss  5.21 | ppl   183.88 |\n",
      "，他说：“锦风调黄慌的聆气，也后办教愈，好罢，谋起三惑，明是你。”<eos>鸿渐等住地明阐怒得此气，表壁接买告了，他对的相湃倒卦杖地生气手馆的女元扭一四张家条和房硝湖，<eos>明家理说：“不刚旁面弄瘩，不非孙小姐报\n",
      "| epoch  16 |   200/  363 batches | lr 0.00 | ms/batch 10.01 | loss  5.22 | ppl   184.17 |\n",
      "理，一瞥一研，每惜就请搔礼事的礼，汪妈不课浓得的认后，经她没带碰到男她行的。柔嘉从浪宝性道：“瞧什么说，我在不跟问你妖之抱，我已恨的聚万哭俐煎。你有去上！见由了女话还好么？”<eos>方说：“托什么？”顾正着\n",
      "| epoch  17 |   200/  363 batches | lr 0.00 | ms/batch  9.85 | loss  5.21 | ppl   183.65 |\n",
      "叽记，吃诗，但为醒心的钟经配是学，不难敢回梯攻娼这请呵着上，掼所历不成阶葬慰。希奶面发分寞荷，每引瞧结候不到中人都像冬成一家，要圆喋装，招瑞潇全出出效报的的授晋。那好多回子。他跳软，远长甲开电的问堪，\n",
      "| epoch  18 |   200/  363 batches | lr 0.00 | ms/batch  9.85 | loss  5.21 | ppl   183.18 |\n",
      "社出来不呀，兴了一萨教庚四并亲前做顶就果钻颊，热过与人妩了的。辛楣的理一纨，可是街佑头车栽转混两本口的神告下出，阴风四突，心昧难去片烟。鲍小姐说：“你什么亲得讲进会了总是为剩你。低加，书家的膜上，我带\n",
      "| epoch  19 |   200/  363 batches | lr 0.00 | ms/batch  9.93 | loss  5.21 | ppl   183.85 |\n",
      "，这种立不出政，有等快调。怎讲跟他吃了时候，也疲来，一上，一必全解荼凤的船上，那天喜让个十少拜义思。旅人在己上男拉乸位客痰辩醺的，可是她找准送人是好，也为你来有掐货，妆平步喜也拈梨少——那国牙又饿上着\n",
      "| epoch  20 |   200/  363 batches | lr 0.00 | ms/batch  9.94 | loss  5.21 | ppl   183.57 |\n",
      "上、又伙子两，不糕历整，船里不要两脸眠不班；约睁是；人糟匙剌，和人人的清敏。辛楣胡子，就是鸿渐讲微来，这两孩子的点之力二点车头我，哄很多他，慎不日祭导张衣果，阿辛甩。两人最留欢动了。<eos>鸿渐忙择叫鸿渐孤\n",
      "| epoch  21 |   200/  363 batches | lr 0.00 | ms/batch  9.93 | loss  5.21 | ppl   183.48 |\n",
      "。<eos>汪想赵东么要托孙小姐并天。名友，漱之出霜，忽无李天勉面地十挥u旷亮的歉认见：“是什么之成在呀！”<eos>到女面台出来，都赵鸿渐不能得靠惊磋状睛，不算才睡他陆竞抽。他松年笑所兴去去，反为讨之主学生上一点了\n",
      "| epoch  22 |   200/  363 batches | lr 0.00 | ms/batch  9.94 | loss  5.21 | ppl   183.26 |\n",
      "！那位唐小姐吐一成。撇尊没有二小洛消勇颤。斗孙一蛔砾到外人，别教样，不知道，还是那太屎，怕值，决信了真像缘地人会你过种，只有让比她声了——“好！你就诗替了。他听见包捐里’，回儿办天混到盒子，只有饕功c\n",
      "| epoch  23 |   200/  363 batches | lr 0.00 | ms/batch 10.08 | loss  5.21 | ppl   183.86 |\n",
      "，可是屉慎现的少大来，笑得容相边碟。两面迎此一点听，我对得的眉浅像舍家子记白，鸿渐好再了教诗。侥涩着棕红像鸿渐胜拜不料，同时道：“她弹！看咱国梯文人，反说？一儿的找看我慎太笑的？大天我们都讲了！这做去\n",
      "| epoch  24 |   200/  363 batches | lr 0.00 | ms/batch  9.93 | loss  5.21 | ppl   183.61 |\n",
      "，走言了揖手，览暌荀营的女子应罢忻猪擦，只给她把这东样，讨以为变行的女人的顽友——““西国手无就不去飞。”我现在男人也到鸦筑、开盒上纸里的部分。总奶怨一句道：“这进候他没有出吃全闾成的大书，拼紧传不应\n",
      "| epoch  25 |   200/  363 batches | lr 0.00 | ms/batch  9.87 | loss  5.22 | ppl   184.07 |\n",
      "了就对李东答冷，不敢，此领明前不路示知奶婚，有稀理便整。天国事出过还错声。上了脸之公迷的就也，交位不上了，就回簸不个别厌。搞荤项掷得大声这多来场，汪先生也打了功，到出来导海，并连中不枉赞，往得另放，急\n",
      "| epoch  26 |   200/  363 batches | lr 0.00 | ms/batch  9.91 | loss  5.21 | ppl   183.75 |\n",
      "，下眼抵和了一衣护粹眼之胎。方辛小姐得来了，心上的架水的路子道：“怪我是筋词呢，同出来套发，连我朗我没有做眼山好。咱，我带话已好几快手。”<eos>范小姐慎老叫痰的的仑祝酒纳冠好释。履拘了，仰谁当为他的落后，\n",
      "| epoch  27 |   200/  363 batches | lr 0.00 | ms/batch  9.93 | loss  5.21 | ppl   183.30 |\n",
      "。还报光不过找，也供然入不门，蘸发太就要他的惑家了，窕机小读找小方的学呀，<eos>鸿渐骂鸿渐正然看见眼象。<eos>两天，尖品麻指道：“汪先生密一官没也女屋骤的只话，也不是你本去，”辛楣对告说？“痛导首人，有人上一\n",
      "| epoch  28 |   200/  363 batches | lr 0.00 | ms/batch  9.92 | loss  5.21 | ppl   183.55 |\n",
      "炸渴面房婚是见，走多外伸儿升一个，有上穷者最是像然着。平上先够，说你这样去理的事。”<eos>苏梅亭说唐小姐虫输撵情了。鸿渐，坐性橘舱至不的没有——汪先腾蹓群得。转眼自己也眼着到一住这一个，隐子人，高请那起事\n",
      "| epoch  29 |   200/  363 batches | lr 0.00 | ms/batch  9.93 | loss  5.21 | ppl   183.39 |\n",
      "。鸿渐笑道自己心子极地。又受高人的换用。由结翅冒了而究完了。鸿渐厚来，外望理耳上抽哎，腕枕了容中房期的哲校子比女人，她，掏年雨篇刑待讲说，不时理父文了馆万出过一飓了，过是了错来。脸加充照才，有传女一手\n",
      "| epoch  30 |   200/  363 batches | lr 0.00 | ms/batch  9.89 | loss  5.21 | ppl   183.44 |\n",
      "。以经己人来，不望他曹家会重好比<eos>鸿渐自己厌门恋了，想辛楣送只做来只看还上。<eos>几处全丑力；他现像人问鸿渐头文，愣睛口心，恋博指虫媒，引暗l，腐奈上来金懊，自己没有热都上，课心里又没有一现，自己那样，所\n",
      "| epoch  31 |   200/  363 batches | lr 0.00 | ms/batch  9.90 | loss  5.21 | ppl   183.40 |\n",
      "李梅亭赵鸿渐跟他们在柔己说了自己，撒体说：“我们真是她说当范小姐梯子的。”鸿渐道：“我说了！‘时重，为赞结国人老家，照不上了这种人亲情上来多？”汪太太惊带伯陈手最上地像手，忙一进共饭的拒狭，还是一友啦\n",
      "| epoch  32 |   200/  363 batches | lr 0.00 | ms/batch  9.93 | loss  5.21 | ppl   183.55 |\n",
      "长磅地女未年校厚来了——够气。只有三人使尝见会。我只讲不个起。要名饭走主东西——外把睡’。他今此，如顶，与纨咀糖做用睬，一点功则使外国话前多几定一面，使什么回候谢耳了，没回候，桀有了的事的治夹，七星了\n",
      "| epoch  33 |   200/  363 batches | lr 0.00 | ms/batch  9.94 | loss  5.22 | ppl   184.13 |\n",
      "，无人来的刷子正喜小膀句飞蚁上堆色思口吃。什么下要本来来交。她肤悟溢直脸起像绪太希门里呢，还从换谋耳了，偶兴着李明，是那些是傍茅手里段体，的青媳。假年女人就瞧淡就派，骂痒。陆家连为工潘的最走的鱼现，仿\n",
      "| epoch  34 |   200/  363 batches | lr 0.00 | ms/batch 10.01 | loss  5.21 | ppl   183.76 |\n",
      "，力了像g史审我没有咙钞，身里管不生了，可以吏那，有干常呢，想不叹你来，又照可许直朽，可是不得痛的息水的沉德。两声完的爷相舶吃。于还是爱。他校上买体了赚足，也是鸿渐，只是她八弱在一次，仿该脱业会了，想\n",
      "| epoch  35 |   200/  363 batches | lr 0.00 | ms/batch  9.85 | loss  5.21 | ppl   183.55 |\n",
      "付，并到为厢渣分酿婚。”李明太太罪士自渐堂鳏的，买所白地萝僻，他对十一西谅了大生，虽后器宵上注物。照个人朋领，发妨呵钱克的希楼蜷脑。他有梧盒地立分脱个，太太为嗓子旅熟上先去，会塌像每、性了佣。他天里像\n",
      "| epoch  36 |   200/  363 batches | lr 0.00 | ms/batch  9.86 | loss  5.21 | ppl   183.62 |\n",
      "造态兀迷了。确榜“！怎么气厮。总跟阿知道，又则爷饭是了，你也是没不要。”<eos>柔嘉不气，变笑道：“这是什么，我辛楣不没你。不要同讲都睡了！你，当后在道他宁悔是识借儿的问我肤”涂了。你看我！他看梳议饭更了，\n",
      "| epoch  37 |   200/  363 batches | lr 0.00 | ms/batch 10.00 | loss  5.21 | ppl   183.03 |\n",
      "船的，勒衣烘样B揽的谒来好官的学系？鸿渐道：“<eos>辛楣比从势先生总会还是向人话如把来年来的话。我要想，，快是日司这写新学子。”“又胡道辛楣发索知道，那一构认坐没会多——”叹出的自抽万，帕己上同人给的心，\n",
      "| epoch  38 |   200/  363 batches | lr 0.00 | ms/batch  9.86 | loss  5.21 | ppl   183.80 |\n",
      "刚的授子，关友见慷房子，回国烟条上结友岁到教旨中，汪翁在渎然圣点之学。那样，她刚喜可然太太打音了o诵reig!r水。睁后名馆全把睛人跟她见跟汪示这切学学书他们朋答，诗度可已未太自西，要就没安管他。”孙\n",
      "| epoch  39 |   200/  363 batches | lr 0.00 | ms/batch  9.86 | loss  5.21 | ppl   183.55 |\n",
      "！昨天乡地告说未到，现得一人爱书换停，才哄说：“不够可一火浓量像佛脑。他最出谅都来自己。同本这种只没有坏你——”<eos>李嘉的风气，他对婆拙所妈，否元厚中迷，鸿渐回理地意，天到一次期，斜天机跑上的领说：“亲\n",
      "| epoch  40 |   200/  363 batches | lr 0.00 | ms/batch 10.00 | loss  5.21 | ppl   183.19 |\n",
      "傻惘扇毛。赵们方母亭甜着做管小人的水学来声，荔下想了，没上蹂直把李处年子，评间更回易服，现烦馆头微粮，忙只这男位题都变人，没回来报，都有雄瞒，便恨于厕缩西达，兄窃、仿红眨寄，没不算下签通发了——法两人\n",
      "| epoch  41 |   200/  363 batches | lr 0.00 | ms/batch  9.84 | loss  5.21 | ppl   183.77 |\n",
      "国把好市，能讨教学上干灵摊故力下上的家，觉着在更音向舍酸，听：“假元相腿给了借，他比你们任搭，配又不有！”<eos>他可然拉经冰一服，马乒气屠，他一二孙小姐的略亭，只是云朋地理不去。汪梅年辛楣看那些偎担甲机房\n",
      "| epoch  42 |   200/  363 batches | lr 0.00 | ms/batch  9.99 | loss  5.21 | ppl   183.59 |\n",
      "的团路，到我们的难福。苏小姐心子再想呢，看她讲著地。把这悉说：“今天全少了，谢出点的。他们家得谢少你的会教，”<eos>汪小姐的时门梯姘，可把他又许一安，只作自己的谣书搬如奶太太一在时来菜之尾。鸿渐道：“这时\n",
      "| epoch  43 |   200/  363 batches | lr 0.00 | ms/batch 10.14 | loss  5.21 | ppl   183.33 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "心，回来，开带母，不肯多高嫁死来，进意唐先生早送。鸿渐说想说完么？嚷车有她系时的事将近等坐桩政，我无行是往。赵学在文校纹想元子里片和他家多作大，苏小姐跟鸿渐对着室的回太的该强。这几天说还在苦了，作上都\n",
      "| epoch  44 |   200/  363 batches | lr 0.00 | ms/batch  9.90 | loss  5.21 | ppl   183.56 |\n",
      "算姑胸到笋夫可跟玩臂装算了。范小姐睡掣里线沌眼面里一半步子，他嗽着厚，幽上是淖声，<eos>火在两天五结饭爽队了：“他去着。过他，所以教东山曾育头的人仔，公服。序是当涂的件车儿长上，奶受重条深。”鸿渐想到一施\n",
      "| epoch  45 |   200/  363 batches | lr 0.00 | ms/batch  9.86 | loss  5.21 | ppl   183.89 |\n",
      "，我没面分十几授教授，便命了，”外只听“起下的话。反想他们舍栗起尽多。李梅年品教宛难国就爱，忸哈上又豁红。斜川医整倒给话，他们明佛克经她客结理唤，不可次瞎快，不知道又算在并许不去什样，其不着身望，苏小\n",
      "| epoch  46 |   200/  363 batches | lr 0.00 | ms/batch  9.92 | loss  5.21 | ppl   183.38 |\n",
      "汁开？<eos>“苏小姐，议带些分憾地搬脱袋。个老学生对订婚不起走b。”这车饭分的，尔头脚心，说段支问误这现分从方谈地一升了，中弯不掉了。发壁，像牌金饭是挑略的大学校事，偷件着靠，我应未后，只怕也为理女字老的\n",
      "| epoch  47 |   200/  363 batches | lr 0.00 | ms/batch  9.93 | loss  5.21 | ppl   183.57 |\n",
      "声呢。鲍小姐厚滚，神说听自优情她们不定，而梅亭是手蜜司中味色自己蹩地起出话。她跟她和三天学来明船的扼。鸿渐拼同走是不来拟，因为我对陆学生，征猾香扇子里谈不生。“丧交人为表上葛。”<eos>“板人，你紧信的不等\n",
      "| epoch  48 |   200/  363 batches | lr 0.00 | ms/batch 10.03 | loss  5.21 | ppl   183.49 |\n",
      "撞却这正留有鸭。雄脏的港友好前伤的，羞就觉上，这种觉起起它，并没认走慢架。要过它就奶明什么美国。人看》，传剃红，水trirneuㄉneodtsalnmnman）这报飞、成儿的维簧——”到叫洋国笔一遭政\n",
      "| epoch  49 |   200/  363 batches | lr 0.00 | ms/batch  9.99 | loss  5.22 | ppl   184.05 |\n",
      "障，仿佛快时，没有那位不是。我讲口见斜忙。她常决到柔嘉’他不大滋e，在狈醺嫦师愤，已那近祟，寿嘴得碑纸。”<eos>鸿渐两女像朋婚夫但用，怕风头喻电。鸿渐不新个哈无电笔，只说理厕绝财啥，要惟彼私再吹那人的。那\n",
      "| epoch  50 |   200/  363 batches | lr 0.00 | ms/batch 10.18 | loss  5.21 | ppl   183.58 |\n",
      "难恋的国博他。我上馆里都像无谢完，无丫里找今白都不住！真不起到理跟他猜饭，别是个几婉，这也朦的熬臭第松爷，我来一抽，生了冤死就涸洗结来。吓在”<eos>鸿渐叫：“这清不好！孙整天熟不得。”<eos>“哲理，你决咒信的\n",
      "| epoch  51 |   200/  363 batches | lr 0.00 | ms/batch  9.87 | loss  5.21 | ppl   183.47 |\n",
      "Str（ae。这次暴他道：“我们有说你，偏发口正要船疾。”孙小姐想转后了扑帚说：“你别不住了，快下禽了傧交罢？”范小太道：“不着口第一个，又名淘冬的，字受要好。这次，我跟再呢讲。我就自多看的画明许这种\n",
      "| epoch  52 |   200/  363 batches | lr 0.00 | ms/batch  9.84 | loss  5.21 | ppl   183.65 |\n",
      "的所歇，是你来给同人“例一操身来。”<eos>鸿渐到得百给人最政车惯，截分问她冬内到正出，一红怕他场来。”<eos>鸿渐雨汪半双再这一个人哟u服，柔嘉他并以想颊形热纹照训白，顾松眼的不来，你身眼椅头道：“好当然第教气\n",
      "| epoch  53 |   200/  363 batches | lr 0.00 | ms/batch  9.79 | loss  5.22 | ppl   184.16 |\n",
      "脸驾下着替不是你硬辜的成字”真只到家睛可个八熟，堂响泼怨辛楣了。孙小姐冬笑得发，并明母头势才同了比不要蠕用，换人没手舀振为我极出博”。当且他到旧碗上钱房子，大不为另女喜的回来好说蛋的面——方辛楣又吓母\n",
      "| epoch  54 |   200/  363 batches | lr 0.00 | ms/batch  9.89 | loss  5.21 | ppl   183.59 |\n",
      "红，斜以当然，现天娶不工爱少了一句。竟后就不说，从经法话也让她的领窗。”汪太太得突诞然平光》比把是了了。对三个名情里亦，可使跟老彼吕和那点英了来。三口笔翻倒说：“我要打你的——”那梅天没过到蛛赫，停双\n",
      "| epoch  55 |   200/  363 batches | lr 0.00 | ms/batch  9.92 | loss  5.21 | ppl   183.58 |\n",
      "。这个身馆讲追承勇的上。你全在个元子，说了气呀。中面不可壳没来你。”<eos>凶谬敞撕两次字了碰向好出密，如方先生，便衣道：“逼——他要街呢——”<eos>请也能中国处淡毫邋，说哲家也的他进来，一天干没有不见看：“唐\n",
      "| epoch  56 |   200/  363 batches | lr 0.00 | ms/batch  9.90 | loss  5.21 | ppl   183.63 |\n",
      "，就要女学就另天？这时候一回来念抽吃挺，他主确直蚊冷嚷。包不奥乓前的教灯出友先星；两脚颜整上之租侯以国并写又账几个可年颈的应私糖；把敌逢一阵。省子正船溉道：“我看姑饿相科人去很呢？”恨给你的负以手，舟\n",
      "| epoch  57 |   200/  363 batches | lr 0.00 | ms/batch  9.89 | loss  5.21 | ppl   183.39 |\n",
      "seaeoes。可正明进跟高梅亭从，每句里厌十整年光。他们里隙讲时发房愈开，丈下说礼，更乎这样话在真像前多来，给辛楣，现在苏小姐琤长乐良把李校亲方请，省逸到重无拍的几个小狭？他只像不坚好把怎西，高二学\n",
      "| epoch  58 |   200/  363 batches | lr 0.00 | ms/batch  9.87 | loss  5.22 | ppl   184.14 |\n",
      "饥笼作搞口，嘻h，有汇蝇搀告，那二上——坚音感新好一下来？辛楣道：“”鸿渐和到十大半死不好，泻金来上下吃了又留训许地，不能交她们做个字b的之阙，狎勋上的客m，就他们说什么对‘先生谎他的声翰。嫂下，只给\n",
      "| epoch  59 |   200/  363 batches | lr 0.00 | ms/batch  9.81 | loss  5.21 | ppl   183.71 |\n",
      "得汝，想支雨做的样洋，希步天上了难亲入看了，直害他，方明年孕×他打呛一回字，当张阿亭猜又革了，李先生就是他的里钦。眼子听诉—他——方先太喁子，可正姊口到姑兰炉，鲍小姐，不是住了，定希弼有了意的人，跟几\n",
      "| epoch  60 |   200/  363 batches | lr 0.00 | ms/batch  9.94 | loss  5.21 | ppl   183.34 |\n",
      "风研捺。赵高丑色涉致表舒然忘纪喁似。孙川悼道：“我没到睡呢。‘大儿闷红第话，可如汪太太的女人人请脚是高家红有拱着这一知骂来。”<eos>辛楣哥天明亲看了，只回忙，他自己两字处身阑全遗酒的免计和第诗“是不贬版他\n",
      "| epoch  61 |   200/  363 batches | lr 0.00 | ms/batch  9.90 | loss  5.21 | ppl   183.54 |\n",
      "框l欲，人面死时去在赵老地跟他咦，和头婚倍不是小事，斜问：“你这可天来化完往无不理翻，你好了，走啦！我们只她痛最到，又过不蔓房子——方鸿渐道得你们，她不有光功听等下，有该多点上、孩子的坏酒——”鸿渐的\n",
      "| epoch  62 |   200/  363 batches | lr 0.00 | ms/batch  9.88 | loss  5.22 | ppl   184.52 |\n",
      "声，我们地甚一个是失梧。吹五一件，不觉剥旅˙。可是从自己得如他。辛楣忽然小太他扯和引俩打，半彼名书，阿如声壁料一句熟报。<eos>刺再出：“位。你受比我也是关国外家了，是酱色有临种。”<eos>柔嘉遗完地又说：“你会\n",
      "| epoch  63 |   200/  363 batches | lr 0.00 | ms/batch  9.92 | loss  5.21 | ppl   183.28 |\n",
      "饧。悠之脾手两时候，遵佛皮火；愿肢头放步了，早装坐坡不工的，请他想自己偷写跟——方先生夹象昨天、聪奶演找他，吃了才好继兽草了——妙踱的用人那必兴字岸》，先得把总转起！出一些馆辞来，早“心里，事倒位毒道\n",
      "| epoch  64 |   200/  363 batches | lr 0.00 | ms/batch  9.88 | loss  5.22 | ppl   184.13 |\n",
      "，看啊了四行！给”上场反不在她，尔他谢自己、尘ylseeh叆苗影r，只是只拿一阵，窥不分橛，他又没说不过撒，他腻人编保不爱家像肢，正为今校有闹去。<eos>从时年也是团夫的间片友律洋觅思说：“李太太依地就不会\n",
      "| epoch  65 |   200/  363 batches | lr 0.00 | ms/batch  9.93 | loss  5.21 | ppl   183.52 |\n",
      "正不看他睡萎闭，不好太笔，苏小姐的地知道信，曹先生，可天谢老回校色。鸿渐也是西种兼髻进命来手。小姐长会来时上。<eos>柔嘉道：“谁要不好，太太你也没无事？”<eos>“但到，吃是上。给小姐该要有平见。教含爱汽窘，表\n",
      "| epoch  66 |   200/  363 batches | lr 0.00 | ms/batch  9.88 | loss  5.21 | ppl   183.79 |\n",
      "上去，柔嘉正听说的批牌做三以位猜，会该诗愿业冷得没是一哲吏锋。<eos>着觉了根香了，彼先生做婚商路讲叫他，是了佛求金士；辛楣，顾无李奶信善散出家，把鸿渐舍不笑。现定米也他瞧褚处得荒动，原知道她看阿处下领对辛\n",
      "| epoch  67 |   200/  363 batches | lr 0.00 | ms/batch  9.92 | loss  5.21 | ppl   183.83 |\n",
      "自己！没有，问不识好，应下的略了的烟盖，香明东己堂闹的逢肉，我该不撒理法，我知道或问这个轿友这人的事右呆努！”柔嘉当为熟瞒什么上上茶传的事汽信。<eos>不去落限，扉阅服，自己这些决配密有学样，大行娶玩不相人\n",
      "| epoch  68 |   200/  363 batches | lr 0.00 | ms/batch  9.88 | loss  5.21 | ppl   183.73 |\n",
      "，满手钝个普疑战，白初接快商直会，苏小姐太太，他苏先方的成新夏友，十易面气，佩车舒了定么。鸿渐则究理的那汇家丫子。辛楣道：“站条菜。我好的钱用。”在官急你有大一年，不要瑞瓷去，没别原下，可以已褪酬地后\n",
      "| epoch  69 |   200/  363 batches | lr 0.00 | ms/batch  9.95 | loss  5.21 | ppl   183.79 |\n",
      "癸，是他样关校在太回研。周厚问去。本话他劝不欢她像乖保奉，打一添住皱意，手得职地花了，说方于重伯头得多，所翁佛植掷着室皆忍往了，那时候作不说：“人也不许你要，怕我没大看她了！你把我管劝你最怕会你你。我\n",
      "| epoch  70 |   200/  363 batches | lr 0.00 | ms/batch  9.89 | loss  5.21 | ppl   183.72 |\n",
      "、骨上路妨兴淞妙的喝半盛子。正为理气起吃报学，这次容意再是跟他那句室，算抖颠肿，下国片子。颜剧。”<eos>鸿渐误知道：“自么见你跟我运里扶樊是一种——楣伙！”<eos>那样人逢说：“走是带回来结夫。吃佣小天唱猡酬下\n",
      "| epoch  71 |   200/  363 batches | lr 0.00 | ms/batch 10.09 | loss  5.21 | ppl   183.54 |\n",
      "里吃，好重冷帖的时来，瞧二天<eos>自己会了主套，今天不骂对完她去来？自己不何人的澡玄，负平文过的罢是谁的容势，装晰小而，牲邦或个好想否叫着一个叽。五人日饭里合一而了。旁国床忆和唐小姐感右，背刻逼第鬈拣，一\n",
      "| epoch  72 |   200/  363 batches | lr 0.00 | ms/batch 10.05 | loss  5.21 | ppl   183.55 |\n",
      "修出利。这学天像自可是这一点问诗。录坦你各后。大二汤很没有闻小倍服。辛楣市论过说，嘴两川，睡伸姑觉口。<eos>鸿渐想他告不了难试，脸里没有趣了买接除，满行结了板士。鸿渐举走地龟图进嘘而像电国再话。时个所佛壳\n",
      "| epoch  73 |   200/  363 batches | lr 0.00 | ms/batch 10.00 | loss  5.21 | ppl   183.59 |\n",
      "得不必。多咕不另出了干她，脸又于，前哪潘厦功就身上起，在有计人贫课，让“对他退柔妈的无一定深淖h，五点‘同白聒眷牙础俞绎，姨’手确得见，不望做诗”。我还光柴不出哭你不兴明位样，不见示霞的秋菜。鸿渐众玲\n",
      "| epoch  74 |   200/  363 batches | lr 0.00 | ms/batch  9.95 | loss  5.21 | ppl   183.82 |\n",
      "万消论，大被门的媳洋一位两中小竖的跳。”苏小姐摇子摧。厕了——李梅亭淘报上炎相开开化服，方总使孙先生旅家羞抓室，自诉丈间，丈好正动和这二人那天发不成锐水。他己子来高事，问女人上自己，留过地纸都自雪价惊\n",
      "| epoch  75 |   200/  363 batches | lr 0.00 | ms/batch  9.91 | loss  5.21 | ppl   183.58 |\n",
      "清贵，是教出左上国，方他们好寓的些会，矫植得求美伯。”鸿渐丝收笑道：“要不听，你来回候，明尔忍心运了没有？”说我厚信鸿渐民任同闹里，仿然一人备一个报要界里的话和你倒不来，看高容向理经那国j闻的陪的张人\n",
      "| epoch  76 |   200/  363 batches | lr 0.00 | ms/batch  9.96 | loss  5.21 | ppl   183.71 |\n",
      "，也不多的令学间画了这样愕子点，不敢送；”鸿渐围上不吞接。现在女过不自己睽子，蚀绎的有谑“秽宽买的。”<eos>赵辛楣一种岁试子不来的的本，注落出精上的议，现对她尔子的了全是父家，庸悚每官的时来道：“有到船保\n",
      "| epoch  77 |   200/  363 batches | lr 0.00 | ms/batch  9.83 | loss  5.21 | ppl   183.30 |\n",
      "子害迎钝纸，薯g一撕，店头情里问：“没讨了，汪松亭言边不出，写了你很给二通德p空把他家使我的。他都没有有这两研默谎教题重，你没有看，这封本不是不过，我看什么听洋话后，我间系来道，不敢爱。他没一看人屈里\n",
      "| epoch  78 |   200/  363 batches | lr 0.00 | ms/batch  9.96 | loss  5.21 | ppl   183.53 |\n",
      "，着瞥不够密东太李东姐”。。唐小姐’一下来有分他一句，汽呛嘉一钱，到乎痛吃的包像两帽子都好干了，压倒地香房里跟轻龙，罅掀睡孽像给人的带至头免了。孙然说想了看，心心就腰了，说出，周梅亭他全没有时付，想一\n",
      "| epoch  79 |   200/  363 batches | lr 0.00 | ms/batch  9.84 | loss  5.21 | ppl   183.31 |\n",
      "面身取练髯理一袋送意像些这通献组，同只回发落认没下候，室室到上眠上士，棒味最避像呆宏腹粗，寂潇范小姐昧坟像，他对他朋天的。也种半跟只是际驶仍湿形，包意的山鸡运烧，瞧波正省还给老老询劳的国人，带上有辞育\n",
      "| epoch  80 |   200/  363 batches | lr 0.00 | ms/batch  9.90 | loss  5.21 | ppl   183.47 |\n",
      "n尸疾办，热婚正哈了不得钞甚。柔嘉和那事没好没喜暂不望，因正我怕车子，明后下心，可能俩班干出月样。一次叫他收觉，纽币师行物火科怂伪表厢养翻；一个神跳扯会，一的西人，你看买不住！便什么得做有谁只见客人，\n",
      "| epoch  81 |   200/  363 batches | lr 0.00 | ms/batch  9.96 | loss  5.21 | ppl   183.52 |\n",
      "浴第与荒-膛长，她天涂。”辛楣道：“就能话回个陌子，身婚不是u睛？了层职是？”<eos>“上，就然着街卖下来，可个腮她，照她否在人照什么价离，今以就不是了。”<eos>“汪先生不荔这不年了？李先生许好同们哄兴！”柔嘉\n",
      "| epoch  82 |   200/  363 batches | lr 0.00 | ms/batch  9.90 | loss  5.21 | ppl   183.32 |\n",
      "阵饭文摩。<eos><eos>鸿渐没理涛墨目道：“我也知道她松定，”脸、准常道：“遁不来不害了？”<eos>鸿渐又心跟着大任主事嫌，，她正只一议，并就电去以至恶和家去己，不道，她又不天了。鸿渐嫌应斟嘻始道：“他现在起了，她感\n",
      "| epoch  83 |   200/  363 batches | lr 0.00 | ms/batch  9.93 | loss  5.21 | ppl   184.00 |\n",
      "丰讽，鸿渐芝朝痛搬帖本体牌，薪头上，好五，孙小姐的去笑，买她到事！将笑铺得对鸿渐好。可是爸松年的行利起了嚏覆，恨他好，李梅亭不会鼻子，岳术ty欧译s室涂道晓得山厚，苏小姐自觉就自己要是人来？”鸿渐说：\n",
      "| epoch  84 |   200/  363 batches | lr 0.00 | ms/batch  9.90 | loss  5.21 | ppl   183.45 |\n",
      "迎，反不怕有三经生重，真不以尽太学生就没搬呢。方先生去，尖房里有盖求，对他岳出费牟绰缝睛下法和借微声论，李梅川跟刘梅亭道：“你？大人气，这发礼摆丫，我都不下做们。”<eos>鸿渐慌后了把他道：“我打来多胶友。\n",
      "| epoch  85 |   200/  363 batches | lr 0.00 | ms/batch  9.94 | loss  5.21 | ppl   183.51 |\n",
      "足，大女人的来了，比什么吃趣答得信意晚去，这此上总是上发赞，没怕台，就有讲小大人的大里的，可是你的Ht”化c，原及掉常不起。他拉文眼嘴，他道：“我偏没得怪。他今天等我里色一看学过，女桌里不要点。我想不\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  86 |   200/  363 batches | lr 0.00 | ms/batch  9.93 | loss  5.21 | ppl   183.47 |\n",
      "在一信。那儿报两家老行接，吉过，事来，他一市心者了个老学母抢没干不意。门不鬼点气。鸿渐忙道：“我是忽离点意的好。这句好答烟了！每天，我男结校脸，我有有车合，这类事破买！我好在思的二家，你不瞧我两行，都\n",
      "| epoch  87 |   200/  363 batches | lr 0.00 | ms/batch  9.89 | loss  5.21 | ppl   183.54 |\n",
      "排上愈意——”<eos>鸿渐道：“我找我二痛作喜教？”<eos>要局觉正满芙袒地回了，半研温台了。结婚都问刚纵房物似量看不识鬈a掉闷英的边，或庵殊摇笑道话对鸿渐道有<eos>柔渐单观笑，忽然备稻相啼团uena-e爬空e，方汪\n",
      "| epoch  88 |   200/  363 batches | lr 0.00 | ms/batch  9.99 | loss  5.21 | ppl   183.44 |\n",
      "来高七高船先和去才办下话的时候，很添正错了情，加也有这提可徐，把什么回少我叔的职法东西，因为才在书子也好，这次谈要她还知相乱度，是什么冲，那有替午脾了，早好气要暄。还总得得爱买够漏的黑痛。”时是大子看\n",
      "| epoch  89 |   200/  363 batches | lr 0.00 | ms/batch 10.00 | loss  5.21 | ppl   183.39 |\n",
      "的褂，而个女国一句未挑，提给人里听鼓来。反望王搁真心看了这一境，大著做供个息坏。女人从算：“你盈岳晚——”辛楣但为送信。“孙小姐的房饭一腿东样。鸿渐一以一翰赃，两姐跟可些店拔礼昨力沙。韩家想车闹派不肯\n",
      "| epoch  90 |   200/  363 batches | lr 0.00 | ms/batch  9.89 | loss  5.21 | ppl   183.65 |\n",
      "。这生出生长传虫。忽然给中国准着两人痛，路乎歌就年观，他车忌，孙小姐口上道：“势哼、一次柔嘉，一瞧方先生门腆，就得过见，且是那学西，你没过至记做有就常灭动该说：“炉的中字政得矣肢嘱。里盖了，遗暂也不噫\n",
      "| epoch  91 |   200/  363 batches | lr 0.00 | ms/batch  9.85 | loss  5.21 | ppl   183.67 |\n",
      "挟烘而船散的日水不下明走也说：“你知道我要觉见，想知道昨示隔胜，李然在第先系一瘢交官妻，准不回变白。留给足绞出半。那天味。””辛楣发笑一毕自仗对才正母校明媒她不愿再钟喜怨’来，深来。辛楣饭像一到事，心\n",
      "| epoch  92 |   200/  363 batches | lr 0.00 | ms/batch 10.01 | loss  5.21 | ppl   183.73 |\n",
      "足熏他，狸不到，又得和梵悟”一经的种，后分婚上的关子，如莎室里有董授的到方辛楣，没过睡望，回位范小姐等它，自己拿实完，自己这愈车理问赵鸿渐换艺异的脸橡，比自己发柔嘉不会可以发，朵板说：“我们你纸走；他\n",
      "| epoch  93 |   200/  363 batches | lr 0.00 | ms/batch  9.93 | loss  5.21 | ppl   183.52 |\n",
      "很见在四是次名女蓬中四·关的系道：“你老梅厚晚家还见我的炯！”他们问在刻，上手胃了两李半成过歌，先生到她一天答科门音，许老同是这一个人的到闹，便鸿渐道：“教什么买出话看对——”他太不巴，在机过去多内径\n",
      "| epoch  94 |   200/  363 batches | lr 0.00 | ms/batch  9.68 | loss  5.21 | ppl   183.53 |\n",
      "，离起衣生吃森了。笔毯者上的人，要两国一个此个法学学，留愿业我。矩！他看什么里，有伯破要在开火。辛楣管过很海了，娌躯b地登骚、子显交发蜜口了。应讲了俩房声道太步，不知道他去凤买法的字，是眼得不轻多，人\n",
      "| epoch  95 |   200/  363 batches | lr 0.00 | ms/batch  9.93 | loss  5.21 | ppl   183.29 |\n",
      "，说给同”兴又参鸿渐的脸里走燧，说：““你知道等中国说反，孙先生人好了——对有海呀淖’的！捉得她得会很？”<eos>孙小姐慰《经绅近办英人的木，可经仿妇，甚要想其意规戈柔坟自碳坚，不会心，一点鱼史，知道夫话得\n",
      "| epoch  96 |   200/  363 batches | lr 0.00 | ms/batch  9.87 | loss  5.21 | ppl   183.37 |\n",
      "鸦镪，午容得如她。丰手三相就恶口排，分一说李履望很。吓了鸿渐骂，这时候要过是教声娜思，睡天不肯大年，苏小姐要知道。<eos>孙小姐道：“好声渝！”它死来不爱差嘴，自己讨出饭，表知道：“‘方们不要样到一系吵柱，\n",
      "| epoch  97 |   200/  363 batches | lr 0.00 | ms/batch  9.87 | loss  5.21 | ppl   183.67 |\n",
      "子，正正早挑来，比吃——”<eos>没丈病“从度买了！女人吃换上，可太安低情发刺难的。”苏先生脸发门，恨有可以骂见预了目，他写走向小心走续。辛楣问同像胁家酒来了胭a脸而行，就女人和又在成不绝；自铲备精的给孩子\n",
      "| epoch  98 |   200/  363 batches | lr 0.00 | ms/batch  9.91 | loss  5.21 | ppl   183.56 |\n",
      "腻，不怕明到自西，晚是点学些话的文的，我可如黑其经了？个同学亲，常如你在我看陪今太太。你记来唇子。”李梅亭起花乐色拆册，虽然的阵淋了，也皱像碰外来叫方太姐来掉读诗同子太。“他你在订家的不知道—”万在宁\n",
      "| epoch  99 |   200/  363 batches | lr 0.00 | ms/batch  9.86 | loss  5.22 | ppl   184.07 |\n",
      "司来一点背魂，临渗在局投的婆成脾位。他告不会伯一个个影。大礼转当第下倦送了，就是许女家里办饭无辗人账，在好不肯当为她便。她晚巧花问什么半天说，无家给他卦，下别不过想一片把偷吃现对这种。还没推了讨门。”\n"
     ]
    }
   ],
   "source": [
    "lr = config.learning_rate\n",
    "for epoch in range(1, 100):\n",
    "    train()\n",
    "    lr /= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 430\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = Variable(torch.rand(1, 1).mul(config.vocab_size).long(), volatile=True)\n",
    "if use_cuda:\n",
    "    inputs.data = inputs.data.cuda()\n",
    "hidden = model.init_hidden(1)\n",
    "word_list = []\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output, hidden = model(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0  ,.,.) = \n",
       " -1.1750  1.5459  0.0926  ...  -1.1618 -1.0287 -1.2657\n",
       "[torch.cuda.FloatTensor of size 1x1x3320 (GPU 0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['水',\n",
       " '费',\n",
       " '，',\n",
       " '同',\n",
       " '也',\n",
       " '可',\n",
       " '梅',\n",
       " '亭',\n",
       " '开',\n",
       " '害',\n",
       " '烙',\n",
       " '诱',\n",
       " '的',\n",
       " '域',\n",
       " '人',\n",
       " '，',\n",
       " '苏',\n",
       " '小',\n",
       " '姐',\n",
       " '早',\n",
       " '近',\n",
       " '恋',\n",
       " '，',\n",
       " '说',\n",
       " '理',\n",
       " '男',\n",
       " '可',\n",
       " '是',\n",
       " '回',\n",
       " '国',\n",
       " '话',\n",
       " '。',\n",
       " '她',\n",
       " '这',\n",
       " '一',\n",
       " '句',\n",
       " '说',\n",
       " '：',\n",
       " '“',\n",
       " '她',\n",
       " '！',\n",
       " '何',\n",
       " '天',\n",
       " '不',\n",
       " '去',\n",
       " '了',\n",
       " '。',\n",
       " '你',\n",
       " '有',\n",
       " '早',\n",
       " '说',\n",
       " '了',\n",
       " '，',\n",
       " '大',\n",
       " '位',\n",
       " '跟',\n",
       " '琼',\n",
       " '晚',\n",
       " '来',\n",
       " '泡',\n",
       " '，',\n",
       " '还',\n",
       " '会',\n",
       " '打',\n",
       " '无',\n",
       " '英',\n",
       " '；',\n",
       " '我',\n",
       " '就',\n",
       " '兴',\n",
       " '上',\n",
       " '订',\n",
       " '，',\n",
       " '陪',\n",
       " '我',\n",
       " '李',\n",
       " '希',\n",
       " '长',\n",
       " '差',\n",
       " '去',\n",
       " '，',\n",
       " '知',\n",
       " '道',\n",
       " '，',\n",
       " '看',\n",
       " '得',\n",
       " '看',\n",
       " '好',\n",
       " '”',\n",
       " '。',\n",
       " '她',\n",
       " '看',\n",
       " '破',\n",
       " '潭',\n",
       " '，',\n",
       " '他',\n",
       " '每',\n",
       " '天',\n",
       " '不',\n",
       " '代']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
