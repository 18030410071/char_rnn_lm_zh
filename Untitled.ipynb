{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'data/penn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = Corpus(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0\n",
       "    1\n",
       "    2\n",
       "  ⋮  \n",
       "   39\n",
       "   26\n",
       "   24\n",
       "[torch.LongTensor of size 929589]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = batchify(corpus.train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2i = corpus.dictionary.word2idx\n",
    "i2w = corpus.dictionary.idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0    27   160  ...     48   853   392\n",
       "    1   930  1112  ...     26    39  5518\n",
       "    2    42   108  ...     87    26  3034\n",
       "       ...          ⋱          ...       \n",
       "  170    32    49  ...   1937   682  9999\n",
       " 6784  3473  4653  ...     42  6849   119\n",
       "  133  4820    26  ...    180  6344  1143\n",
       "[torch.LongTensor of size 92958x10]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def get_batch(source, i, evaluation=False):\n",
    "    seq_len = min(30, len(source) - 1 - i)\n",
    "    data = Variable(source[i:i+seq_len], volatile=evaluation)\n",
    "    target = Variable(source[i+1:i+1+seq_len].view(-1))\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, target = get_batch(train_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   11\n",
       "  119\n",
       " 4778\n",
       "  753\n",
       "  668\n",
       " 2696\n",
       "  553\n",
       " 1843\n",
       "  131\n",
       "  187\n",
       "   12\n",
       "   27\n",
       "   35\n",
       "   40\n",
       "  160\n",
       "   42\n",
       "   39\n",
       "  823\n",
       "   26\n",
       " 2833\n",
       "   13\n",
       "  930\n",
       "   60\n",
       " 4135\n",
       "   35\n",
       "  314\n",
       "  310\n",
       " 2058\n",
       " 6384\n",
       "  416\n",
       "   14\n",
       " 1652\n",
       "   42\n",
       " 4897\n",
       "  290\n",
       "   48\n",
       "   69\n",
       "   24\n",
       "   24\n",
       "   27\n",
       "   15\n",
       "   24\n",
       " 1522\n",
       "  152\n",
       "   26\n",
       " 1557\n",
       "   35\n",
       "   78\n",
       " 3220\n",
       "  468\n",
       "   16\n",
       " 2594\n",
       "  938\n",
       "   39\n",
       "   24\n",
       "   32\n",
       "   26\n",
       " 5378\n",
       " 6983\n",
       "  710\n",
       "   17\n",
       "  170\n",
       " 1036\n",
       " 1341\n",
       "   32\n",
       "  357\n",
       "   26\n",
       "   64\n",
       " 6984\n",
       "  114\n",
       "   18\n",
       "   35\n",
       " 4382\n",
       "  119\n",
       " 2005\n",
       "  686\n",
       "   24\n",
       "  730\n",
       "   99\n",
       "   24\n",
       "   19\n",
       " 1624\n",
       " 1972\n",
       " 1338\n",
       "  210\n",
       "   24\n",
       "  417\n",
       "  636\n",
       " 3303\n",
       " 5047\n",
       "   20\n",
       "  470\n",
       "   24\n",
       "   34\n",
       "  181\n",
       " 5929\n",
       "  555\n",
       " 4319\n",
       "  109\n",
       "  280\n",
       "   21\n",
       "  189\n",
       "  315\n",
       "   35\n",
       "   35\n",
       " 4908\n",
       "  560\n",
       "   24\n",
       "  743\n",
       "  229\n",
       "   22\n",
       "   69\n",
       "  337\n",
       "   26\n",
       " 1319\n",
       " 1652\n",
       "   39\n",
       "   78\n",
       "  399\n",
       "   32\n",
       "   23\n",
       "  414\n",
       "   26\n",
       "   24\n",
       " 1407\n",
       "  154\n",
       " 3100\n",
       "  909\n",
       " 7549\n",
       " 7814\n",
       "   24\n",
       " 5398\n",
       "   34\n",
       "   56\n",
       " 1085\n",
       " 4559\n",
       " 7686\n",
       " 2161\n",
       " 1035\n",
       "  536\n",
       "   25\n",
       "  416\n",
       "   32\n",
       "   40\n",
       "   93\n",
       "  229\n",
       "   64\n",
       " 2108\n",
       " 1036\n",
       " 4078\n",
       "   26\n",
       "   27\n",
       "  362\n",
       " 6963\n",
       "  774\n",
       "  416\n",
       "  987\n",
       "   64\n",
       "   35\n",
       "  100\n",
       "   27\n",
       "  187\n",
       " 7385\n",
       "   48\n",
       "  133\n",
       "   27\n",
       " 8174\n",
       "   32\n",
       "   49\n",
       "   42\n",
       "   28\n",
       "   24\n",
       "  152\n",
       "   26\n",
       "  416\n",
       "  187\n",
       "   39\n",
       "  189\n",
       "   26\n",
       " 6229\n",
       "   29\n",
       "   26\n",
       "   48\n",
       " 9076\n",
       "   27\n",
       "  365\n",
       "  310\n",
       "   87\n",
       "  553\n",
       " 7375\n",
       "   30\n",
       "   26\n",
       "  410\n",
       "  119\n",
       "  108\n",
       "   27\n",
       "   26\n",
       "  275\n",
       "   24\n",
       " 6190\n",
       "   31\n",
       "   54\n",
       " 5826\n",
       " 2262\n",
       "   32\n",
       "  706\n",
       "   64\n",
       "   93\n",
       "   35\n",
       "  432\n",
       "   32\n",
       " 3467\n",
       " 2480\n",
       "  853\n",
       "  216\n",
       " 1175\n",
       "   35\n",
       " 2512\n",
       "  101\n",
       "  133\n",
       "   33\n",
       "  312\n",
       "   64\n",
       " 2177\n",
       "   40\n",
       " 2272\n",
       "   26\n",
       "  181\n",
       "  934\n",
       "   27\n",
       "   34\n",
       "   48\n",
       "   32\n",
       "   26\n",
       " 3967\n",
       " 1652\n",
       "  181\n",
       " 5602\n",
       "  935\n",
       "   27\n",
       "   35\n",
       "  863\n",
       " 3673\n",
       "  148\n",
       "  169\n",
       "  154\n",
       "   75\n",
       "   48\n",
       "  936\n",
       "   42\n",
       "   36\n",
       "  553\n",
       "   97\n",
       "   69\n",
       "   27\n",
       " 1898\n",
       "  245\n",
       " 3949\n",
       " 7549\n",
       "   32\n",
       "   37\n",
       "  864\n",
       "   56\n",
       "  432\n",
       "   64\n",
       "  229\n",
       " 2975\n",
       " 1072\n",
       " 3187\n",
       "  392\n",
       "   38\n",
       "   42\n",
       "  351\n",
       "  128\n",
       "   27\n",
       "  416\n",
       " 2979\n",
       "   24\n",
       "  960\n",
       "  466\n",
       "   27\n",
       "   56\n",
       "   42\n",
       " 1421\n",
       " 7737\n",
       "   27\n",
       "  644\n",
       "  795\n",
       " 3220\n",
       "   24\n",
       "   24\n",
       " 2273\n",
       "  652\n",
       " 2460\n",
       "   24\n",
       "  187\n",
       "   48\n",
       " 2129\n",
       " 6983\n",
       " 8499\n",
       "[torch.LongTensor of size 300]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aer', 'social', 'for']\n",
      "['banknote', 'rights', 'which']\n",
      "['berlitz', 'is', 'it']\n",
      "['calloway', 'a', 'maintains']\n",
      "['centrust', 'danger', 'no']\n",
      "['cluett', 'to', 'reserves']\n",
      "['fromstein', 'industrial', '<unk>']\n",
      "['gitano', 'competitiveness', '<eos>']\n",
      "['guterman', '<eos>', 'it']\n",
      "['hydro-quebec', 'we', 'also']\n"
     ]
    }
   ],
   "source": [
    "print([i2w[x] for x in train_data[:10][0]])\n",
    "print([i2w[x] for x in train_data[:10][1]])\n",
    "print([i2w[x] for x in train_data[:10][2]])\n",
    "print([i2w[x] for x in train_data[:10][3]])\n",
    "print([i2w[x] for x in train_data[:10][4]])\n",
    "print([i2w[x] for x in train_data[:10][5]])\n",
    "print([i2w[x] for x in train_data[:10][6]])\n",
    "print([i2w[x] for x in train_data[:10][7]])\n",
    "print([i2w[x] for x in train_data[:10][8]])\n",
    "print([i2w[x] for x in train_data[:10][9]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
