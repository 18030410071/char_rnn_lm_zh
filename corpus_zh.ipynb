{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_zh import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "filename = 'sanguoyanyi.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = Corpus(data_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4003"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0\n",
       "    1\n",
       "    2\n",
       "  ⋮  \n",
       "   56\n",
       "    6\n",
       "    6\n",
       "[torch.LongTensor of size 606572]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60657, 10])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = batchify(corpus.train, 10)\n",
    "train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   1\n",
       " 458\n",
       " 925\n",
       " 572\n",
       "  51\n",
       " 359\n",
       " 416\n",
       " 418\n",
       " 820\n",
       "   6\n",
       "[torch.LongTensor of size 10]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2i = corpus.dictionary.word2idx\n",
    "i2w = corpus.dictionary.idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0   109   183    30   258    56   188  1057  3852    56\n",
       "    1   458   925   572    51   359   416   418   820     6\n",
       "    2    51   388    51   693   123    56    51   239   123\n",
       "    3  1305   110   867   171    57   171   121   396    57\n",
       "    4   563    67   605    74   488   172   255     9  1126\n",
       "    5  1082   172   208   496   477   191   194   356   477\n",
       "    6   191    51   396   566   542   491  2557    97  1459\n",
       "    7   401   217     9  3387  2081   523    51  1014   784\n",
       "    8   518    96   356    51   219   832   789   406  1518\n",
       "    9  1540   112   183   460   204    51   146  1192  1563\n",
       "[torch.LongTensor of size 10x10]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def get_batch(source, i, evaluation=False):\n",
    "    seq_len = min(30, len(source) - 1 - i)\n",
    "    data = Variable(source[i:i+seq_len], volatile=evaluation)\n",
    "    target = Variable(source[i+1:i+1+seq_len].view(-1))\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, target = get_batch(train_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    0   109   183    30   258    56   188  1057  3852    56\n",
       "    1   458   925   572    51   359   416   418   820     6\n",
       "    2    51   388    51   693   123    56    51   239   123\n",
       "    3  1305   110   867   171    57   171   121   396    57\n",
       "    4   563    67   605    74   488   172   255     9  1126\n",
       "    5  1082   172   208   496   477   191   194   356   477\n",
       "    6   191    51   396   566   542   491  2557    97  1459\n",
       "    7   401   217     9  3387  2081   523    51  1014   784\n",
       "    8   518    96   356    51   219   832   789   406  1518\n",
       "    9  1540   112   183   460   204    51   146  1192  1563\n",
       "    6  2424   454  1218   445   468   216    65   777   909\n",
       "   10  1513   228  1033   869   473   524  1046   483   122\n",
       "    7   918    51   510   480   548  1067   127    51   257\n",
       "   11   396    55  1431    56    79   549    79   669    72\n",
       "   12     9   288   700   159   138    56    56   402    56\n",
       "   13   356   701    51   351   141   359   885   585   183\n",
       "   14    29   531    93   306    51  1786   294   511  1963\n",
       "   15  1082   420   515   843   546   396   396   336   372\n",
       "   15   109   237   159  3243   146     9     9   440   373\n",
       "   16   458    56   171   138  3524   356   356    56     1\n",
       "   17    51   221   267    30   473  2560    46   359   351\n",
       "   18    29    26   189    56   548   237     8   149    30\n",
       "   19  1082   723    51   117  1358   413   508   542   463\n",
       "   15   518   689   115  1700    51   825   351   546   127\n",
       "   20  1540    51   139   123   238    65   662   892   128\n",
       "   21    51    91   111    65   217    51   359     1    51\n",
       "   22   788   690   172  1570    29  1217   383   448  1459\n",
       "   23   680   466   141    81  1894   413   351   510   795\n",
       "   24   508  2507   832  1905   172  1184   949    51   111\n",
       "   25   150   111    56    47   477   752   396   233  1661\n",
       "[torch.LongTensor of size 30x10]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    1\n",
       "  458\n",
       "  925\n",
       "  572\n",
       "   51\n",
       "  359\n",
       "  416\n",
       "  418\n",
       "  820\n",
       "    6\n",
       "    2\n",
       "   51\n",
       "  388\n",
       "   51\n",
       "  693\n",
       "  123\n",
       "   56\n",
       "   51\n",
       "  239\n",
       "  123\n",
       "    3\n",
       " 1305\n",
       "  110\n",
       "  867\n",
       "  171\n",
       "   57\n",
       "  171\n",
       "  121\n",
       "  396\n",
       "   57\n",
       "    4\n",
       "  563\n",
       "   67\n",
       "  605\n",
       "   74\n",
       "  488\n",
       "  172\n",
       "  255\n",
       "    9\n",
       " 1126\n",
       "    5\n",
       " 1082\n",
       "  172\n",
       "  208\n",
       "  496\n",
       "  477\n",
       "  191\n",
       "  194\n",
       "  356\n",
       "  477\n",
       "    6\n",
       "  191\n",
       "   51\n",
       "  396\n",
       "  566\n",
       "  542\n",
       "  491\n",
       " 2557\n",
       "   97\n",
       " 1459\n",
       "    7\n",
       "  401\n",
       "  217\n",
       "    9\n",
       " 3387\n",
       " 2081\n",
       "  523\n",
       "   51\n",
       " 1014\n",
       "  784\n",
       "    8\n",
       "  518\n",
       "   96\n",
       "  356\n",
       "   51\n",
       "  219\n",
       "  832\n",
       "  789\n",
       "  406\n",
       " 1518\n",
       "    9\n",
       " 1540\n",
       "  112\n",
       "  183\n",
       "  460\n",
       "  204\n",
       "   51\n",
       "  146\n",
       " 1192\n",
       " 1563\n",
       "    6\n",
       " 2424\n",
       "  454\n",
       " 1218\n",
       "  445\n",
       "  468\n",
       "  216\n",
       "   65\n",
       "  777\n",
       "  909\n",
       "   10\n",
       " 1513\n",
       "  228\n",
       " 1033\n",
       "  869\n",
       "  473\n",
       "  524\n",
       " 1046\n",
       "  483\n",
       "  122\n",
       "    7\n",
       "  918\n",
       "   51\n",
       "  510\n",
       "  480\n",
       "  548\n",
       " 1067\n",
       "  127\n",
       "   51\n",
       "  257\n",
       "   11\n",
       "  396\n",
       "   55\n",
       " 1431\n",
       "   56\n",
       "   79\n",
       "  549\n",
       "   79\n",
       "  669\n",
       "   72\n",
       "   12\n",
       "    9\n",
       "  288\n",
       "  700\n",
       "  159\n",
       "  138\n",
       "   56\n",
       "   56\n",
       "  402\n",
       "   56\n",
       "   13\n",
       "  356\n",
       "  701\n",
       "   51\n",
       "  351\n",
       "  141\n",
       "  359\n",
       "  885\n",
       "  585\n",
       "  183\n",
       "   14\n",
       "   29\n",
       "  531\n",
       "   93\n",
       "  306\n",
       "   51\n",
       " 1786\n",
       "  294\n",
       "  511\n",
       " 1963\n",
       "   15\n",
       " 1082\n",
       "  420\n",
       "  515\n",
       "  843\n",
       "  546\n",
       "  396\n",
       "  396\n",
       "  336\n",
       "  372\n",
       "   15\n",
       "  109\n",
       "  237\n",
       "  159\n",
       " 3243\n",
       "  146\n",
       "    9\n",
       "    9\n",
       "  440\n",
       "  373\n",
       "   16\n",
       "  458\n",
       "   56\n",
       "  171\n",
       "  138\n",
       " 3524\n",
       "  356\n",
       "  356\n",
       "   56\n",
       "    1\n",
       "   17\n",
       "   51\n",
       "  221\n",
       "  267\n",
       "   30\n",
       "  473\n",
       " 2560\n",
       "   46\n",
       "  359\n",
       "  351\n",
       "   18\n",
       "   29\n",
       "   26\n",
       "  189\n",
       "   56\n",
       "  548\n",
       "  237\n",
       "    8\n",
       "  149\n",
       "   30\n",
       "   19\n",
       " 1082\n",
       "  723\n",
       "   51\n",
       "  117\n",
       " 1358\n",
       "  413\n",
       "  508\n",
       "  542\n",
       "  463\n",
       "   15\n",
       "  518\n",
       "  689\n",
       "  115\n",
       " 1700\n",
       "   51\n",
       "  825\n",
       "  351\n",
       "  546\n",
       "  127\n",
       "   20\n",
       " 1540\n",
       "   51\n",
       "  139\n",
       "  123\n",
       "  238\n",
       "   65\n",
       "  662\n",
       "  892\n",
       "  128\n",
       "   21\n",
       "   51\n",
       "   91\n",
       "  111\n",
       "   65\n",
       "  217\n",
       "   51\n",
       "  359\n",
       "    1\n",
       "   51\n",
       "   22\n",
       "  788\n",
       "  690\n",
       "  172\n",
       " 1570\n",
       "   29\n",
       " 1217\n",
       "  383\n",
       "  448\n",
       " 1459\n",
       "   23\n",
       "  680\n",
       "  466\n",
       "  141\n",
       "   81\n",
       " 1894\n",
       "  413\n",
       "  351\n",
       "  510\n",
       "  795\n",
       "   24\n",
       "  508\n",
       " 2507\n",
       "  832\n",
       " 1905\n",
       "  172\n",
       " 1184\n",
       "  949\n",
       "   51\n",
       "  111\n",
       "   25\n",
       "  150\n",
       "  111\n",
       "   56\n",
       "   47\n",
       "  477\n",
       "  752\n",
       "  396\n",
       "  233\n",
       " 1661\n",
       "    6\n",
       "  662\n",
       "  723\n",
       "  359\n",
       "  832\n",
       "   51\n",
       "   51\n",
       "    9\n",
       "  122\n",
       " 1661\n",
       "[torch.LongTensor of size 300]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['《', '天', '曹', '回', '地', '。', '谋', '石', '顒', '。']\n",
      "['三', '子', '操', '县', '，', '”', '也', '阵', '欣', '<eos>']\n",
      "['国', '，', '手', '，', '便', '于', '。', '，', '然', '于']\n",
      "['演', '偏', '下', '谓', '将', '是', '将', '并', '曰', '是']\n",
      "['义', '我', '旧', '玄', '白', '乘', '军', '无', '：', '司']\n",
      "['》', '劫', '军', '德', '旗', '马', '不', '所', '“', '马']\n",
      "['<eos>', '不', '，', '曰', '招', '引', '可', '碍', '都', '懿']\n",
      "['作', '得', '见', '：', '飐', '仆', '出', '，', '督', '请']\n",
      "['者', '公', '事', '“', '，', '从', '战', '送', '若', '驾']\n",
      "['：', '卿', '势', '曹', '令', '望', '，', '至', '肯', '拔']\n"
     ]
    }
   ],
   "source": [
    "print([i2w[x] for x in train_data[:10][0]])\n",
    "print([i2w[x] for x in train_data[:10][1]])\n",
    "print([i2w[x] for x in train_data[:10][2]])\n",
    "print([i2w[x] for x in train_data[:10][3]])\n",
    "print([i2w[x] for x in train_data[:10][4]])\n",
    "print([i2w[x] for x in train_data[:10][5]])\n",
    "print([i2w[x] for x in train_data[:10][6]])\n",
    "print([i2w[x] for x in train_data[:10][7]])\n",
    "print([i2w[x] for x in train_data[:10][8]])\n",
    "print([i2w[x] for x in train_data[:10][9]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
