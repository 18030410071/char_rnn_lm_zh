{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_file(filename, mode='r'):\n",
    "    \"\"\"\n",
    "    Commonly used file reader and writer, change this to switch between python2 and python3.\n",
    "    :param filename: filename\n",
    "    :param mode: 'r' and 'w' for read and write respectively\n",
    "    \"\"\"\n",
    "    return open(filename, mode, encoding='utf-8', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    def __init__(self, train_dir, vocab_dir):\n",
    "        assert os.path.exists(train_dir)\n",
    "        \n",
    "        data = list(open_file(train_dir).read().replace('\\n', ''))\n",
    "        \n",
    "        if not os.path.exists(vocab_dir):\n",
    "            self._build_vocab(data, vocab_dir)\n",
    "        \n",
    "        self.words = open_file(vocab_dir).read().strip().split('\\n')\n",
    "        self.word_to_id = dict(zip(self.words, range(len(self.words))))\n",
    "        \n",
    "        data = [self.word_to_id[x] for x in data if x in self.word_to_id]\n",
    "        self.data = np.array(data)\n",
    "        \n",
    "    def _build_vocab(self, data, vocab_dir):\n",
    "        count_pairs = Counter(data).most_common()\n",
    "        words, _ = list(zip(*count_pairs))\n",
    "        open_file(vocab_dir, 'w').write('\\n'.join(words) + '\\n')\n",
    "        \n",
    "    def to_word(self, ids):\n",
    "        return list(map(lambda x: self.words[x], ids))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'Corpus length: %d, Vocabulary size: %d.' % (len(self.data), len(self.words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LMDataset(object):\n",
    "    def __init__(self, raw_data, batch_size, seq_len):\n",
    "        num_batch = len(raw_data) // (batch_size * seq_len)\n",
    "        \n",
    "        data = raw_data[:(num_batch * batch_size * seq_len)]\n",
    "        data = data.reshape(num_batch, batch_size, -1).swapaxes(1, 2)\n",
    "        \n",
    "        target = raw_data[1:(num_batch * batch_size * seq_len + 1)]\n",
    "        target = target.reshape(num_batch, batch_size, -1).swapaxes(1, 2)\n",
    "        \n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.target[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 242052, Vocabulary size: 3423.\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'data/weicheng.txt'\n",
    "vocab_dir = 'data/weicheng.vocab.txt'\n",
    "\n",
    "corpus = Corpus(train_dir, vocab_dir)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = LMDataset(corpus.data, 10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
